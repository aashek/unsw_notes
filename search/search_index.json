{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Obsidian Notes \u00b6 Publish your public notes with MkDocs Hello World! \u00b6 The index.md in the /docs folder is the homepage you see here. The folders in /docs appear as the main sections on the navigation bar. The notes appear as pages within these sections. For example, Note 1 in Topic 1","title":"Obsidian Notes"},{"location":"#obsidian-notes","text":"Publish your public notes with MkDocs","title":"Obsidian Notes"},{"location":"#hello-world","text":"The index.md in the /docs folder is the homepage you see here. The folders in /docs appear as the main sections on the navigation bar. The notes appear as pages within these sections. For example, Note 1 in Topic 1","title":"Hello World!"},{"location":"COMP3161/TODO%203161/","text":"","title":"TODO 3161"},{"location":"COMP3161/Truth%20Symbols/","text":"\u21d2 \u2192 \u2283 \u21d4 \u2261 \u2194 \u00ac \u02dc ! \u2227 \u00b7 & \u2228 + \u2225 \u21ae \u2295 \u22bb \u2262 \u22a4 T 1 \u25a0 \u22a5 F 0 \u25a1 \u2200 () \u2203 \u2254 \u2261 :\u21d4","title":"Truth Symbols"},{"location":"COMP3161/latex/","text":"b) Define a scope-checking judgement, similar to the ok judgement from the lectures. It should check (a) that all names of variables and functions are used only within their scopes; and (b) that names used in variable (or function) position are indeed the names of variables (or functions). Hence, the following expressions should both be rejected: let f (x ) = \u00acx in f (x ) end x is a free variable (unbound) let f (x ) = \u00acx in f (f ) end we need some way to differentiate functions from variable binds. let f (x ) = x (True) in f (False) end when defining, we need some way to invalidate applying a variable as a function The following are examples of things that should be accepted: nested definitions, and shadowed definitions. let f (x ) = let g(y) = \u00acx \u2227 y in g(x ) \u2227 \u00acg(x ) end in f (False) end let f (x ) = x in let f (x ) = f (x ) in f (True) end end Note that the latter example is not a recursive call. (10 marks) $$ \\begin{align*} \\frac{}{\\Gamma \\vdash True \\textbf{ok}} &\\qquad \\frac{}{\\Gamma \\vdash False \\textbf{ok}}\\\\ \\frac{\\Gamma \\vdash e_{1} \\textbf{ ok}} {\\Gamma \\vdash \\text{Not } e_{1} \\textbf{ ok}} &\\qquad \\dfrac{ \\Gamma \\vdash e_{1}\\textbf{ ok} \\quad \\Gamma \\vdash e_2\\textbf{ ok} }{\\Gamma \\vdash \\text{And } e_{1} e_{2} \\textbf{ ok}}\\\\ \\frac{}{\\Gamma \\vdash f(x)\\textbf{ ok}} &\\qquad \\frac{\\text{x bound}, \\Gamma \\vdash e_{1}\\textbf{ ok}\\quad \\text{f bound},\\Gamma \\vdash e_2\\textbf{ ok}} {\\text{ \\(\\Gamma\\vdash\\) Let f x \\(e_1\\) \\(e_2\\) }\\textbf{ ok}}\\ \\ \\dfrac{\\text{f bound}\\in\\Gamma \\quad \\Gamma\\vdash e_{1} \\textbf{ ok}}{\\Gamma\\vdash \\text{Func f \\(e_1\\) }\\textbf{ ok}} &\\qquad \\dfrac{\\text{x bound} \\in \\Gamma}{\\Gamma \\vdash \\text{Var x}\\textbf{ ok}} \\end{align*} $$ $$ \\dfrac{ \\dfrac{}{\\vdash} } {\\text{let f(x)= let g(y) = \\(\\neg\\) x \\(\\wedge\\) y in g(x) \\(\\wedge\\) \\(\\neg\\) g(x) end in f(False) end}} $$ $$ \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x}\\vdash \\text{Var x}} }{\\text{x}\\vdash \\text{Not (Var x)}} \\quad \\dfrac{\\vdash \\text{True}}{\\text{f}\\vdash\\text{f(True)}} }{\\vdash \\text{Let f(Var x) = Not x in f(True) end}} $$ f = (\\la x. -> x) $$\\dfrac{ \\dfrac{ \\dfrac{ \\dfrac{\\dfrac{}{\\text{x,y}\\vdash(V x)\\textbf{ ok}}}{\\text{x,y}\\vdash \\neg (V x)\\textbf{ ok}} \\quad \\dfrac{}{\\text{x,y}\\vdash (V y)\\textbf{ ok}} }{\\text{x,y}\\vdash \\text{ \\(\\neg\\) (V x) \\(\\wedge\\) (V y)}\\textbf{ ok}} \\quad \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x,g}\\vdash V x\\textbf{ ok}}}{\\text{x,g}\\vdash g((V x))\\textbf{ ok}} \\quad \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x}\\vdash (V x)\\textbf{ ok}} }{\\text{x,g}\\vdash g((V x))\\textbf{ ok}} }{\\text{x,g}\\vdash \\neg g((V x))\\textbf{ ok}} }{\\text{x,g}\\vdash g((V x)) \\wedge \\neg g((V x))\\textbf{ ok}} }{\\text{x} \\vdash\\text{let g(y) = \\(\\neg\\) (V x) \u2227 (V y) in g((V x)) \u2227 \\(\\neg\\) g((V y)) end}\\textbf{ ok}} \\quad \\dfrac{\\dfrac{}{\\vdash\\text{False}\\textbf{ ok}}}{\\text{f}\\vdash\\text{f (False)}\\textbf{ ok}} } {\\text{let f (x ) = let g(y) = \\(\\neg\\) (V x) \u2227 (V y) in g((V x)) \u2227 \\(\\neg\\) g((V x) end in f (False) end}\\textbf{ ok}} $$","title":"Latex"},{"location":"COMP3161/ass/Assignment%200-DESKTOP-8G34FJ6/","text":"b) Define a scope-checking judgement, similar to the ok judgement from the lectures. It should check (a) that all names of variables and functions are used only within their scopes; and (b) that names used in variable (or function) position are indeed the names of variables (or functions). Hence, the following expressions should both be rejected: let f (x ) = \u00acx in f (x ) end x is a free variable (unbound) let f (x ) = \u00acx in f (f ) end we need some way to differentiate functions from variable binds. let f (x ) = x (True) in f (False) end when defining, we need some way to invalidate applying a variable as a function The following are examples of things that should be accepted: nested definitions, and shadowed definitions. let f (x ) = let g(y) = \u00acx \u2227 y in g(x ) \u2227 \u00acg(x ) end in f (False) end let f (x ) = x in let f (x ) = f (x ) in f (True) end end Note that the latter example is not a recursive call. (10 marks) $$ \\begin{align*} \\frac{}{\\Gamma \\vdash True \\textbf{ok}} &\\qquad \\frac{}{\\Gamma \\vdash False \\textbf{ok}}\\\\ \\frac{\\Gamma \\vdash e_{1} \\textbf{ ok}} {\\Gamma \\vdash \\text{Not } e_{1} \\textbf{ ok}} &\\qquad \\dfrac{ \\Gamma \\vdash e_{1}\\textbf{ ok} \\quad \\Gamma \\vdash e_2\\textbf{ ok} }{\\Gamma \\vdash \\text{And } e_{1} e_{2} \\textbf{ ok}}\\\\ \\frac{}{\\Gamma \\vdash f(x)\\textbf{ ok}} &\\qquad \\frac{\\text{x bound}, \\Gamma \\vdash e_{1}\\textbf{ ok}\\quad \\text{f bound},\\Gamma \\vdash e_2\\textbf{ ok}} {\\text{ \\(\\Gamma\\vdash\\) Let f x \\(e_1\\) \\(e_2\\) }\\textbf{ ok}}\\ \\ \\dfrac{\\text{f bound}\\in\\Gamma \\quad \\Gamma\\vdash e_{1} \\textbf{ ok}}{\\Gamma\\vdash \\text{Func f \\(e_1\\) }\\textbf{ ok}} &\\qquad \\dfrac{\\text{x bound} \\in \\Gamma}{\\Gamma \\vdash \\text{Var x}\\textbf{ ok}} \\end{align*} $$ $$ \\dfrac{ \\dfrac{}{\\vdash} } {\\text{let f(x)= let g(y) = \\(\\neg\\) x \\(\\wedge\\) y in g(x) \\(\\wedge\\) \\(\\neg\\) g(x) end in f(False) end}} $$ $$ \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x}\\vdash \\text{Var x}} }{\\text{x}\\vdash \\text{Not (Var x)}} \\quad \\dfrac{\\vdash \\text{True}}{\\text{f}\\vdash\\text{f(True)}} }{\\vdash \\text{Let f(Var x) = Not x in f(True) end}} $$ f = (\\la x. -> x) $$\\dfrac{ \\dfrac{ \\dfrac{ \\dfrac{\\dfrac{}{\\text{x,y}\\vdash(V x)\\textbf{ ok}}}{\\text{x,y}\\vdash \\neg (V x)\\textbf{ ok}} \\quad \\dfrac{}{\\text{x,y}\\vdash (V y)\\textbf{ ok}} }{\\text{x,y}\\vdash \\text{ \\(\\neg\\) (V x) \\(\\wedge\\) (V y)}\\textbf{ ok}} \\quad \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x,g}\\vdash V x\\textbf{ ok}}}{\\text{x,g}\\vdash g((V x))\\textbf{ ok}} \\quad \\dfrac{ \\dfrac{ \\dfrac{}{\\text{x}\\vdash (V x)\\textbf{ ok}} }{\\text{x,g}\\vdash g((V x))\\textbf{ ok}} }{\\text{x,g}\\vdash \\neg g((V x))\\textbf{ ok}} }{\\text{x,g}\\vdash g((V x)) \\wedge \\neg g((V x))\\textbf{ ok}} }{\\text{x} \\vdash\\text{let g(y) = \\(\\neg\\) (V x) \u2227 (V y) in g((V x)) \u2227 \\(\\neg\\) g((V y)) end}\\textbf{ ok}} \\quad \\dfrac{\\dfrac{}{\\vdash\\text{False}\\textbf{ ok}}}{\\text{f}\\vdash\\text{f (False)}\\textbf{ ok}} } {\\text{let f (x ) = let g(y) = \\(\\neg\\) (V x) \u2227 (V y) in g((V x)) \u2227 \\(\\neg\\) g((V x) end in f (False) end}\\textbf{ ok}} $$","title":"Assignment 0 DESKTOP 8G34FJ6"},{"location":"COMP3161/ass/Assignment%200/","text":"Part A (25 marks) \u00b6 Consider the language of boolean expressions \\(\\mathcal{P}\\) containing just literals (True, False), parentheses, conjunction (\u2227) and negation (\u00ac): P = {True, False, \u00acTrue, \u00acFalse, True \u2227 False, \u00ac(True \u2227 False), . . . } 1. Write down a set of inference rules that define the set \\(\\mathcal{P}\\) . The rules may be ambiguous. (5 marks) $$ \\begin{gather} \\dfrac{}{True Expr}\\\\ \\dfrac{}{False Expr}\\\\ \\dfrac{e Expr}{\\negate e Expr}\\\\ \\dfrac{e Expr}{(e) Expr}\\\\ \\frac{e_1 Expr e_2 Expr}{e_1 \u2227 e_2 Expr}\\; \\end{gather} $$ The operator \u00ac has the highest precedence, and conjunction is right-associative. Define a set of simultaneous judgements to define the language without any ambiguity. (5 marks) We define AExpr, and BExpr, where BExpr has lower precedence than AExpr. $$ \\dfrac{e AExpr}{e BExpr}\\; $$ True and False have equal highest precedence. $$ \\dfrac{}{True AExpr}\\; \\dfrac{}{False AExpr}\\; $$ Negation has the highest precedence. By using parentheses, we increase predecence. $$ \\dfrac{e AExpr}{\u00ace AExpr}\\; \\dfrac{e BExpr}{(e) AExpr} $$ Conjuctions have less precedence then A, hence if we combine an A and a B, we get a B. Right associative means we need the right element to be a BExpr. $$ \\frac{e_1 AExpr e_2 BExpr}{e_1 \u2227 e_2 BExpr}\\; $$ Here is an abstract syntax B for the same language: B ::= Not B | And B B | True | False Write an inductive definition for the parsing relation connecting your unambiguous judgements to this abstract syntax. (5 marks) \\[ Abstract\\ Syntax $$ $$ \\dfrac{i\\in \\{True, False\\}}{(Bool\\ i) \\ AST} \\dfrac{a\\ AST}{(Not\\ a)\\ AST} \\dfrac{a\\ AST\\ \\ b\\ AST}{(And\\ a\\ b)\\ AST} \\] $$ \\text{Parsing Relation} \\[ $$ \\dfrac{i\\in \\{True, False\\}}{i\\ AExpr \\longleftrightarrow(Bool\\ i) \\ AST} \\] \\[ \\frac{ e_1\\ AExpr\\longleftrightarrow\\ e_1' \\ AST \\quad\\quad e_2\\ BExpr\\longleftrightarrow\\ e_2' \\ AST }{ e_1\\ \u2227 \\ e_2 \\ BExpr \\longleftrightarrow\\ (And\\ \\ e_1'\\ e_2') \\ AST }\\; $$ $$ \\dfrac{e\\ AExpr\\longleftrightarrow\\ e' \\ AST} {\u00ace\\ AExpr\\longleftrightarrow\\ (Not \\ e') \\ AST} \\;\\ \\dfrac{e\\ BExpr\\longleftrightarrow\\ e' \\ AST} {(e)\\ AExpr \\longleftrightarrow \\ e' \\ AST } $$ $$ \\dfrac{e\\ AExpr\\longleftrightarrow\\ e' \\ AST} {e\\ BExpr \\longleftrightarrow \\ e' \\ AST } \\] 4. Here is a big-step semantics for the language $$\\begin{gather} &\\dfrac{ \\quad }{ \\mathsf{True} \\Downarrow \\mathsf{True} }(B_1)\\quad &\\dfrac{ \\quad }{ \\mathsf{False} \\Downarrow \\mathsf{False} }(B_2)\\\\ &\\dfrac{ x \\Downarrow \\mathsf{True} }{\\mathsf{Not} x\\Downarrow\\mathsf{False}}(B_3)\\quad &\\dfrac{ x \\Downarrow \\mathsf{False } }{\\mathsf{Not} x\\Downarrow \\mathsf{True}}(B_4)\\\\ &\\dfrac{ x \\Downarrow \\mathsf{False } }{\\mathsf{And} x y \\Downarrow \\mathsf{False}}(B_5)\\quad &\\dfrac{ x \\Downarrow \\mathsf{True} \\quad y \\Downarrow v }{\\mathsf{And} x y \\Downarrow v}(B_6) \\end{gather} $$ a) Show the evaluation of And (Not (And True False)) True with a derivation tree. (5 marks). \\[ \\dfrac {\\dfrac {\\dfrac {\\dfrac{}{True\\ \u21d3\\ True\\;}(B_5)\\ \\dfrac{}{False\\ \u21d3\\ False\\;}(B_6)} {(And\\ \\ True\\ False)\\ \u21d3\\ False}(B_4) } {(Not\\ \\ (And\\ \\ True\\ False))\\ \u21d3\\ True}(B_2) \\;\\dfrac{}{True\\ \u21d3\\ True\\;}(B_5) } {And\\ \\ (Not\\ \\ (And\\ \\ True\\ False))\\ \\ True\\ \u21d3\\ True}(B_4) \\] b) Consider the following inference rule: $$\\dfrac{y \u21d3 False} {And x y \u21d3 False} $$ If we assume that x B holds, is this rule derivable? Is it admissible? And if we don\u2019t assume that x B holds, how does this change your answers? Justify your answers. (5 marks) $$\\text{Assuming x B} $$ The inference rule R cannot be derived. This is because there is no way to construct a tree that looks like: $$\\dfrac{ \\dfrac{y \u21d3 False} {\\vdots } }{And x y \u21d3 False}\\; $$ However this rule is admissible, since it does not add strings to B. In this case if the result is used in the other inference rules, since x holds in B and y holds in B, that result will also hold in B. $$\\text{Not Assuming x B} $$ The inference rule R cannot be derived. This is because there is no way to construct a tree that looks like: $$\\dfrac{ \\dfrac{y \u21d3 False} {\\vdots } }{And x y \u21d3 False}\\; $$ This rule is not admissible with the current assumption, since it adds strings to B. This is because x does not hold in B, and if we use x in the other rules, we will get something is also not admissible in B. \u00b6 Part B (20 marks) \u00b6 Here is a small-step semantics for a language L with True, False and if expressions: L:: True | False | If L then L else L $$ \\begin{gather} \\dfrac{ c \\mapsto c' }{(\\texttt{If} c t e) \\mapsto (\\texttt{If} c' t e) }&(1)\\\\ \\dfrac{ }{(\\texttt{If} \\texttt{True} t e) \\mapsto t }&(2)\\\\ \\dfrac{ }{(\\texttt{If} \\texttt{False} t e) \\mapsto e }&(3) \\end{gather} $$ 1. Show the full evaluation of the term (If True (If True False True) False). (5 marks) \\[ \\begin{align*} &\\text{(If True (If True False True) False)} \\\\ &\\mapsto \\text{If True False True (2)}\\\\ &\\mapsto \\text{False (2)} \\end{align*} \\] Define an equivalent big-step semantics for L. (5 marks) We define: A set of evaluable expressions T A set of values V A relation \u21d3 \u2286 E \u00d7 V T is the set of all closed expressions {t | t ok} and V is the set {True, False}. \\[ \\begin{gather} \\dfrac{}{\\text{$v$\\Downarrow $v$}}\\quad&(L_1)\\\\\\\\ \\dfrac{\\text{ $t_1 \\Downarrow$ True \\quad$t_2 \\Downarrow v_2$}}{\\text{(If $t_1$ then $t_2$ else $t_3 )\\Downarrow v_2$ }}&(L_2)\\\\\\\\ \\dfrac{ \\text{ $t_1 \\Downarrow$ False \\quad$t_3 \\Downarrow v_3$}}{\\text{(If $t_1$ then $t_2$ else $t_3 )\\Downarrow v_3$ }}&(L_3) \\end{gather} \\] 3. Prove that if \\(e \\Downarrow v\\) then \\(e \\stackrel{\\star}{\\mapsto} v\\) , where \\(\\Downarrow\\) is the big-step semantics you defined in the previous question, and \\(\\stackrel{\\star}{\\mapsto}\\) is the reflexive and transitive closure of \\(\\mapsto\\) . Use rule induction on \\(e \\Downarrow v\\) . Assumed Rules \u00b6 $$ \\dfrac{}{e \\stackrel{\\star}{\\mapsto} e}refl \\quad \\dfrac{e \\mapsto e' \\quad e' \\stackrel{\\star}{\\mapsto} e''} {e \\stackrel{\\star}{\\mapsto} e''}trans $$ If \\(e \\Downarrow v\\) then \\(e \\stackrel{\\star}{\\mapsto} v\\) \u00b6 Base Case \\((e=v)\\) , from (A) \u00b6 We must show that \\(v\\stackrel{\\star}{\\mapsto} v\\) , obvious by rule refl. Inductive Case \\((e\\ =\\ (If\\ t_1\\ then\\ t_2\\ else\\ t_3))\\) , from (B) \u00b6 We know that \\(t_1 \\Downarrow True\\) and \\(t_2 \\Downarrow v_2\\) , which gives us the inductive hypotheses: - \\(IH_1 - t_1 \\stackrel{\\star}{\\mapsto} True\\) - \\(IH_2 - t_2 \\stackrel{\\star}{\\mapsto} v_2\\) Showing our overall goal: $$ \\begin{align*} \\text{(If \\(t_1\\) then \\(t_2\\) else \\(t_3\\) )} &\\stackrel{\\star}{\\mapsto}\\text{(If True then \\(t_2\\) else \\(t_3\\) )}&\\text{( \\(IH_1\\) with 1)}\\ &\\stackrel{\\star}{\\mapsto}t_2 &(2)\\ &\\stackrel{\\star}{\\mapsto}\\text{ \\(v_2\\) } &(IH_2)\\ \\end{align*} $$ Inductive Case \\((e\\ =\\ (If\\ t_1\\ then\\ t_2\\ else\\ t_3))\\) , from (C) \u00b6 We know that \\(t_1 \\Downarrow False\\) and \\(t_3 \\Downarrow v_3\\) , which gives us the inductive hypotheses: - \\(IH_1 - t_1 \\stackrel{\\star}{\\mapsto} False\\) - \\(IH_2 - t_3 \\stackrel{\\star}{\\mapsto} v_3\\) Showing our overall goal: $$ \\begin{align*} \\text{(If \\(t_1\\) then \\(t_2\\) else \\(t_3\\) )} &\\stackrel{\\star}{\\mapsto}\\text{(If False then \\(t_2\\) else \\(t_3\\) )}&\\text{( \\(IH_1\\) with 1)}\\ &\\stackrel{\\star}{\\mapsto}t_3 &(3)\\ &\\stackrel{\\star}{\\mapsto}\\text{ \\(v_3\\) } &(IH_2)\\ \\end{align*} $$ Thus, by mathematical induction, we have shown one direction of the equivalence. If \\(e \\stackrel{\\star}{\\mapsto} v\\) then \\(e \\Downarrow v\\) \u00b6 Doing rule induction on the assumption \\(e \\stackrel{\\star}{\\mapsto} v\\) leads to two cases. Base case \\((e=v)\\) , from refl \u00b6 We know that \\(v \\Downarrow v\\) , from rule (A). Inductive case ( \\(e\u21a6e'\\) and \\(e \\stackrel{\\star}{\\mapsto} v\\) ), from trans \u00b6 We have the inductive hypothesis that \\(e'\\Downarrow v\\) , so it suffices to prove the following lemma in order to discharge this case. \\( \\(\\dfrac{s \\mapsto s'\\quad s' \\Downarrow v}{s \\Downarrow v}\\) \\) Transitive Lemma: If \\(e\u21a6e'\\) and \\(e'\u21d3v\\) then \\(e\u21d3v\\) \u00b6 Written as a logical statement, this lemma is: \\( \\(\u2200v. (e\u21a6e')\u2227(e'\u21d3v)\u21d2e\u21d3v\\) \\) Equivalently, this can be stated as: \\( \\((e\u21a6e')\u21d2(\u2200v. e\u2032\u21d3v)\u21d2(e\u21d3v)\\) \\) This formulation lets us proceed by rule induction on the assumption \\(e\u21a6e'\\) , proving for each case for any arbitrary v: \\( \\(\u2200v. \\dfrac{e'\u21d3v}{e\u21d3v}\\) \\) Base Case 1, from rule (2) \u00b6 Here \\(e = \\text{(If True t e)}\\) and \\(e' = t\\) . We have to show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . The only way that assumption could hold, looking at the rules of \u21d3, is if \\(v = t\\) from rule A. Therefore we must show that \\((\\text{If True t e}) \u21d3 t\\) , which is trivial from A and B. Base Case 2, from rule (3) \u00b6 Here \\(e = \\text{(If False t e)}\\) and \\(e' = \\text{e}\\) . We have to show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . The only way that assumption could hold, looking at the rules of \u21d3, is if \\(v =\\text{e}\\) from rule A. Therefore we must show that \\(\\text{(If True t e) \u21d3 e}\\) , which is trivial from A and B. Inductive Case, from rule (1) \u00b6 Here \\(e = \\text{(If c t e)}\\) and \\(e' = \\text{(If c}'\\text{ t e)}\\) . We know that \\(c\u21a6c'\\) , giving the inductive hypothesis that: \\[\u2200v. \\dfrac{c'\u21d3v}{c\u21d3v}IH\\] We must show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . Looking at the rules for \u21d3, the only way that \\(e' \u21d3 v\\) could hold is if there is some \\(v_x\\) such that \\(\\text{c}'\u21d3v_x\\) and \\(\\text{t} \u21d3 v_t\\) and \\(\\text{e} \u21d3 v_e\\) . (which can be proven by rule B and C). Hence by the inductive hypothesis, we have that \\(c\u21d3v_x\\) . Therefore, \\(e \u21d3 v\\) as required. \u00b6 Part C (15 marks) \u00b6 Define a recursive compilation function \\(c : B \u2192 L\\) which converts expressions in \\(B\\) to expressions in \\(L\\) . (5 marks) \\[\\begin{align} c(\\textsf{Not} \\; x) &= \\text{If\\ $c(x)$\\ then\\ False\\ else\\ True}&(C_1)\\\\\\\\ c(\\textsf{And} \\; x \\; y) &= \\text{If $c(x)$ then $c(y)$ else False}&(C_2)\\\\\\\\ c(\\textsf{True}) &= True&(C_3)\\\\\\\\ c(\\textsf{False}) &= False&(C_4) \\end{align} \\] Prove that for all \\(e, e \u21d3 v\\) implies \\(c(e) \u21d3 v\\) , by rule induction on the assumption that \\(e \u21d3 v\\) . (10 marks) For all proofs of induction, I have abbreviated \\(True \\implies \\mathsf{T}\\ and\\ False \\implies \\mathsf{F}\\) . Rule (1) \u00b6 From (1), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{F}\\) and the assumption \\(x \\Downarrow \\mathsf{T}\\) . Hence the statement above we conclude our inductive hypothesis: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{T}&\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{Not}\\ x)=\\mathsf{F}\\) . $$ \\begin{align*} \\dfrac{\\dfrac{}{c(x)\\Downarrow \\mathsf{T}}(I.H.)\\quad\\dfrac{}{\\mathsf{F}\\Downarrow \\mathsf{F}}(B_6)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(\\mathsf{F}\\) else \\(\\mathsf{T}\\) ) \\(\\Downarrow \\mathsf{F}\\) }} { c(\\mathsf{Not} x) \\Downarrow \\mathsf{F} }(C_1) }(L_2) \\end{align*} $$ Rule (2) \u00b6 From (2), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{T}\\) and the assumption \\(x \\Downarrow \\mathsf{F}\\) . Hence the statement above we conclude our inductive hypothesis: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{F}&\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{Not}\\ x)=\\mathsf{T}\\) . $$ \\begin{align*} \\dfrac{\\dfrac{}{c(x)\\Downarrow \\mathsf{F}}(I.H.)\\quad\\dfrac{}{\\mathsf{T}\\Downarrow \\mathsf{T}}(B_5)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(\\mathsf{F}\\) else \\(\\mathsf{T}\\) ) \\(\\Downarrow \\mathsf{T}\\) }} { c(\\mathsf{Not} x) \\Downarrow \\mathsf{T} }(C_1) }(L_2) \\end{align*} $$ Rule (3) \u00b6 From (3), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{F}\\) and the assumption \\(x \\Downarrow \\mathsf{F}\\) . Hence the statement above we conclude our inductive hypotheses: $$ \\begin{align } c(x)&\\Downarrow\\mathsf{F} &\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{And}\\ x\\ y)=\\mathsf{F}\\) . $$ \\begin{align*} \\dfrac{ \\dfrac{}{c(x)\\Downarrow \\mathsf{F}}(I.H_1)\\quad \\dfrac{}{\\mathsf{F}\\Downarrow \\mathsf{F}}(B_6)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(c(y)\\) else \\(\\mathsf{F}\\) ) \\(\\Downarrow \\mathsf{F}\\) }} { c(\\mathsf{And} x y) \\Downarrow \\mathsf{F} }(C_2) }(L_3) \\end{align*} $$ Rule (4) \u00b6 For this proof, I have renamed the value \\(v\\) from the rule, as \\(\\mathsf{v_k}\\) . From (4), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{v_k}\\) and the assumptions \\(x \\Downarrow \\mathsf{T}\\) and \\(y \\Downarrow \\mathsf{v_k}\\) . Hence the statement above we conclude our inductive hypotheses: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{T} &\\quad(I.H_1) \\ \\ c(y)&\\Downarrow \\mathsf{v_k} &\\quad(I.H_2) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{And}\\ x\\ y)=\\mathsf{v_k}\\) . $$ \\begin{align*} \\dfrac{ \\dfrac{}{c(x)\\Downarrow \\mathsf{T}}(I.H_1)\\quad \\dfrac{}{c(y)\\Downarrow \\mathsf{v_k}}(I.H_2)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(c(y)\\) else \\(\\mathsf{F}\\) ) \\(\\Downarrow \\mathsf{v_k}\\) }} { c(\\mathsf{And} x y) \\Downarrow \\mathsf{v_k} }(C_2) }(L_2) \\end{align*} $$ Rule (5) \u00b6 From (5), we declare \\(e = \\mathsf{T}\\) , \\(v = \\mathsf{T}\\) . We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{T}) \\Downarrow \\mathsf{T}\\) . \\[ \\dfrac{}{\\dfrac{T \\Downarrow T}{c(T) \\Downarrow T}} $$ ### Rule (6) From (6), we declare $e = \\mathsf{F}$, $v = \\mathsf{F}$. We can now prove that $c(e) \\Downarrow v$, or in other words $c(e) \\Downarrow \\mathsf{F}$. $$ \\dfrac{}{\\dfrac{F \\Downarrow F}{c(F) \\Downarrow F}} \\] \u00b6 Part D. \u00b6 Here is a term in \\(\\lambda\\) -calculus: $$ (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) $$ a) Fully \u03b2-reduce the above \u03bb-term. Show all intermediate beta reduction steps. (5 marks) $$ \\begin{align } (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) &\\mapsto_\\beta\\lambda f. \\lambda x. ((\\lambda f. \\lambda x. f x) f (f x))&\\text{[On \\(n\\) ]}\\ &\\equiv_\\alpha\\lambda f. \\lambda x. ((\\lambda f'. \\lambda x'. f' x') f (f x))&\\text{[ \\(f\\mapsto\\ f'\\) , \\(x\\mapsto\\ x'\\) ]}\\ &\\mapsto_\\beta\\lambda f. \\lambda x. (( \\lambda x'. f x' ) (f x))\\quad&\\text{[On \\(f'\\) ]}\\ &\\mapsto_\\beta\\lambda f. \\lambda x. f (f x)\\quad \\blacksquare &\\text{[On \\(x'\\) ]} \\end{align } $$ b) Identify an \u03b7-reducible expression in the above (unreduced) term. (5 marks) We can reduce the unreduced expression using \\(\\eta\\) -reduction on \\(x\\) . $$ \\begin{align } (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) &\\mapsto_\\eta(\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. f) \\end{align } $$ For question 2 and 3, I will shorthand \\((\u03bbx. \u03bby. x) \\implies \\mathbf{T}\\) and \\((\u03bbx. \u03bby. y) \\implies \\mathbf{F}\\) . \u00b6 Recall that in \u03bb-calculus, booleans can be encoded as binary functions that return one of their arguments: \\( \\(\\begin{align*}\\mathbf{T} \u2261 (\u03bbx. \u03bby. x)\\\\ \\mathbf{F} \u2261 (\u03bbx. \u03bby. y) \\end{align*}\\) \\) Either via L or directly, define a function d : B \u2192 \u03bb which converts expressions in B to \u03bb-calculus. (5 marks) \\[\\begin{align*} d(\\textsf{Not} \\; x) &= (\\lambda x. x\\ \\mathbf{F}\\ \\mathbf{T})\\ d(x)&(D_1)\\\\\\\\ d(\\textsf{And} \\; x \\; y) &= (\\lambda a. \\lambda b.\\ a\\ b\\ a)\\ d(x)\\ d(y)&(D_2)\\\\\\\\ d(\\textsf{True}) &= \\mathbf{T}&(D_3)\\\\\\\\ d(\\textsf{False}) &= \\mathbf{F}&(D_4) \\end{align*} \\] Prove that for all e such that \\(e \u21d3 v\\) it holds that \\(d (e) \\equiv_{\\alpha\\beta\\eta} v'\\) , where \\(v'\\) is the \u03bb-calculus encoding of v. Rule (1) \u00b6 From (1), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{False}\\) and the assumptions \\(x \\Downarrow \\mathsf{True}\\) . From the statement above we have our inductive hypothesis: $$ \\begin{align } d(x)&=d(True)&\\ &=\\mathbf{T}&(I.H.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(False)\\\\ &=\\mathbf{F} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{Not} \\ x) \\equiv_{\\alpha\\beta\\eta} \\mathsf{F}\\) .A $$ \\begin{align } d(\\mathsf{Not} x) &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) d(x)&(D_1)\\ &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) \\mathbf{T} &(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} \\mathbf{F} \\mathsf{T}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} &\\blacksquare\\ \\end{align } $$ Rule (2) \u00b6 From (2), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{True}\\) and the assumptions \\(x \\Downarrow \\mathsf{False}\\) . From the statement above we have our inductive hypothesis: $$ \\begin{align } d(x)&=d(False)&\\ &=\\mathbf{F}&(I.H.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(True)\\\\ &=\\mathbf{T} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{Not} \\ x) \\equiv_{\\alpha\\beta\\eta} \\mathsf{T}\\) . $$ \\begin{align } d(\\mathsf{Not} x) &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) d(x)&(D_1)\\ &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) \\mathbf{F} &(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} \\mathbf{F} \\mathsf{T}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} &\\blacksquare\\ \\end{align } $$ Rule (3) \u00b6 From (3), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{False}\\) and the assumptions \\(x \\Downarrow \\mathsf{False}\\) . From the statement above we have our inductive hypotheses: $$ \\begin{align } d(x)&=d(False)&\\ &=\\mathbf{F}&(I.H.)\\\\ \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(False)\\\\ &=\\mathbf{F} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{And} \\ x\\ y) \\equiv_{\\alpha\\beta\\eta} \\mathsf{F}\\) . $$ \\begin{align } d(\\mathsf{And} x y) &=(\\lambda a. \\lambda b. a b a) d(x) d(y)&(D_2)\\ &=(\\lambda a. \\lambda b. a b a) \\mathbf{F} d(y)&(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}(\\lambda b \\mathbf{F} b \\mathsf{F}) d(y)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} d(y) \\mathbf{F}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} &\\blacksquare\\ \\end{align } $$ Rule (4) \u00b6 For this proof, I have renamed the value \\(v\\) from the rule, as \\(\\mathbf{v_k}\\) . From (4), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathbf{v_k}\\) and the assumptions \\(x \\Downarrow \\mathsf{True}\\) and \\(y \\Downarrow \\mathbf{v_k}\\) . From the statement above we have our inductive hypotheses: $$ \\begin{align } d(x)&=d(True)&\\ &=\\mathbf{T}&(I.H_1.)\\\\ d(y)&=d(\\mathbf{v_k})&(I.H_2.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(\\mathbf{v_k})&\\\\ \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{And} \\ x\\ y) \\equiv_{\\alpha\\beta\\eta} d(\\mathbf{v_k})\\) . $$ \\begin{align } d(\\mathsf{And} x y) &=(\\lambda a. \\lambda b. a b a) d(x) d(y)&(D_2)\\ &=(\\lambda a. \\lambda b. a b a) \\mathbf{T} d(\\mathbf{v_k})&(From I.H_1 and I.H_2.)\\ &\\equiv_{\\alpha\\beta\\eta}(\\lambda b \\mathbf{T} b \\mathbf{T}) d(\\mathbf{v_k})\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} d(\\mathbf{v_k}) \\mathbf{T}\\ &\\equiv_{\\alpha\\beta\\eta}d(\\mathbf{v_k}) &\\blacksquare\\ \\end{align } $$ Rule (5) \u00b6 From (5), we declare \\(e = True\\) and \\(v=True\\) . We also compute \\(v'\\) $$ \\begin{align } v'&=d(True)\\ &=\\mathbf{T} \\end{align } $$ We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{True} ) \\equiv_{\\alpha\\beta\\eta} \\mathbf{T}\\) . $$ \\begin{align} d(True) &\\equiv_{\\alpha\\beta\\eta} \\mathbf{T} &(D_3) \\end{align} $$ Rule (6) \u00b6 From (6), we declare \\(e = False\\) and \\(v=False\\) . We also compute \\(v'\\) $$ \\begin{align } v'&=d(False)\\ &=\\mathbf{F} &(D_4) \\end{align } $$ We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{False} ) \\equiv_{\\alpha\\beta\\eta} \\mathbf{F}\\) . $$ \\begin{align} d(False) &\\equiv_{\\alpha\\beta\\eta} \\mathbf{F} &(D_3) \\end{align} $$ Suppose we added unary local function definitions to our language \\(\\mathcal{P}\\) . Here's an example in concrete syntax: $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{g}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{g}(\\mathsf{True})\\ \\mathsf{end} \\end{array} $$ We limit ourselves to non-recursive bindings (meaning functions can't call themselves), and first-order functions (meaning functions require boolean arguments). a) Extend the abstract syntax for \\(\\mathcal{B}\\) from question A.3 so that it supports the features used in the above example. Use first-order abstract syntax with explicit strings. You don't have to extend the parsing relation. (5 marks) We extend B to $$ \\begin{align} B ::&= &\\mathsf{True}\\ &| &\\mathsf{False}\\ &| &\\mathsf{Not B}\\ &| &\\mathsf{And B B}\\ &| &\\mathsf{Func F B}\\ &| &\\mathsf{Var M}\\ &| &\\mathsf{Let F B B in B End} \\end{align} $$ For my additions: Func F B takes in two arguments, F is the function name and B is the variable. Var M takes in one argument, where M is a variable. Let F B B B takes in four arguments, F is the name of the function, the first B is the assigned variable for F, the second B is the replacement expression, and the third B is the expression we apply the function. An example is Let \"g\" (Var \"x\") (Not \"x\") (F \"g\" True) b) Define a scope-checking judgement, similar to the \\(\\mathbf{ok}\\) judgement from the lectures. It should check (a) that all names of variables and functions are used only within their scopes; and (b) that names used in variable (or function) position are indeed the names of variables (or functions). Hence, the following expressions should both be rejected: $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathit{x})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathit{f})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{x}(\\mathsf{True}) \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathsf{False})\\ \\mathsf{end} \\end{array} $$ The following are examples of things that should be accepted: nullary definitions, nested definitions, and shadowed definitions. $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) =\\ \\quad\\mathsf{let} \\ \\quad\\;\\;\\mathit{g}(\\mathit{y}) = \\neg\\mathit{x}\\wedge\\mathit{y} \\ \\quad\\mathsf{in} \\ \\quad\\;\\; \\mathit{g}(\\mathit{x}) \\wedge \\neg\\mathit{g}(\\mathit{x})\\ \\quad\\mathsf{end}\\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathsf{False})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{x}(\\mathsf{True}) \\ \\mathsf{in} \\ \\quad\\mathsf{let} \\ \\quad\\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{f}(\\mathit{x}) \\ \\quad\\mathsf{in} \\ \\quad\\;\\; \\mathit{f}(\\mathsf{True})\\ \\quad\\mathsf{end}\\ \\mathsf{end} \\end{array} $$ Note that the latter example is not a recursive call. (10 marks) It should check (a) that all names of variables and functions are used only within their scopes (b) that names used in variable (or function) position are indeed the names of variables (or functions). $$ \\begin{gather} &\\dfrac{}{\\Gamma \\vdash True \\mathbf{ok}}\\\\ &\\dfrac{}{\\Gamma \\vdash False \\mathbf{ok}}\\\\ &\\dfrac{\\Gamma \\vdash e_1 \\mathbf{ok}}{\\Gamma \\vdash \\mathsf{Not} (e_1) \\mathbf{ok}}\\\\ &\\dfrac{\\Gamma \\vdash e_1 \\mathbf{ok}\\quad\\Gamma \\vdash e_2 \\mathbf{ok}}{\\Gamma \\vdash \\mathsf{And} (e_1 e_2) \\mathbf{ok}}\\\\ &\\dfrac{(x bound)\\in\\Gamma}{\\Gamma \\vdash (Var x) \\mathbf{ok}}\\\\ &\\dfrac{(f bound)\\in\\Gamma\\quad\\Gamma\\vdash e_1 \\mathbf{ok}}{\\Gamma \\vdash (Func f e_1) \\mathbf{ok}}\\\\ &\\dfrac{(x bound), \\Gamma\\vdash e_1\\quad(f bound) ,\\Gamma\\vdash e_2 \\mathbf{ok}}{\\Gamma \\vdash (Let f x e_1 e_2) \\mathbf{ok}}\\\\ \\end{gather} $$","title":"Part A (25 marks)"},{"location":"COMP3161/ass/Assignment%200/#part-a-25-marks","text":"Consider the language of boolean expressions \\(\\mathcal{P}\\) containing just literals (True, False), parentheses, conjunction (\u2227) and negation (\u00ac): P = {True, False, \u00acTrue, \u00acFalse, True \u2227 False, \u00ac(True \u2227 False), . . . } 1. Write down a set of inference rules that define the set \\(\\mathcal{P}\\) . The rules may be ambiguous. (5 marks) $$ \\begin{gather} \\dfrac{}{True Expr}\\\\ \\dfrac{}{False Expr}\\\\ \\dfrac{e Expr}{\\negate e Expr}\\\\ \\dfrac{e Expr}{(e) Expr}\\\\ \\frac{e_1 Expr e_2 Expr}{e_1 \u2227 e_2 Expr}\\; \\end{gather} $$ The operator \u00ac has the highest precedence, and conjunction is right-associative. Define a set of simultaneous judgements to define the language without any ambiguity. (5 marks) We define AExpr, and BExpr, where BExpr has lower precedence than AExpr. $$ \\dfrac{e AExpr}{e BExpr}\\; $$ True and False have equal highest precedence. $$ \\dfrac{}{True AExpr}\\; \\dfrac{}{False AExpr}\\; $$ Negation has the highest precedence. By using parentheses, we increase predecence. $$ \\dfrac{e AExpr}{\u00ace AExpr}\\; \\dfrac{e BExpr}{(e) AExpr} $$ Conjuctions have less precedence then A, hence if we combine an A and a B, we get a B. Right associative means we need the right element to be a BExpr. $$ \\frac{e_1 AExpr e_2 BExpr}{e_1 \u2227 e_2 BExpr}\\; $$ Here is an abstract syntax B for the same language: B ::= Not B | And B B | True | False Write an inductive definition for the parsing relation connecting your unambiguous judgements to this abstract syntax. (5 marks) \\[ Abstract\\ Syntax $$ $$ \\dfrac{i\\in \\{True, False\\}}{(Bool\\ i) \\ AST} \\dfrac{a\\ AST}{(Not\\ a)\\ AST} \\dfrac{a\\ AST\\ \\ b\\ AST}{(And\\ a\\ b)\\ AST} \\] $$ \\text{Parsing Relation} \\[ $$ \\dfrac{i\\in \\{True, False\\}}{i\\ AExpr \\longleftrightarrow(Bool\\ i) \\ AST} \\] \\[ \\frac{ e_1\\ AExpr\\longleftrightarrow\\ e_1' \\ AST \\quad\\quad e_2\\ BExpr\\longleftrightarrow\\ e_2' \\ AST }{ e_1\\ \u2227 \\ e_2 \\ BExpr \\longleftrightarrow\\ (And\\ \\ e_1'\\ e_2') \\ AST }\\; $$ $$ \\dfrac{e\\ AExpr\\longleftrightarrow\\ e' \\ AST} {\u00ace\\ AExpr\\longleftrightarrow\\ (Not \\ e') \\ AST} \\;\\ \\dfrac{e\\ BExpr\\longleftrightarrow\\ e' \\ AST} {(e)\\ AExpr \\longleftrightarrow \\ e' \\ AST } $$ $$ \\dfrac{e\\ AExpr\\longleftrightarrow\\ e' \\ AST} {e\\ BExpr \\longleftrightarrow \\ e' \\ AST } \\] 4. Here is a big-step semantics for the language $$\\begin{gather} &\\dfrac{ \\quad }{ \\mathsf{True} \\Downarrow \\mathsf{True} }(B_1)\\quad &\\dfrac{ \\quad }{ \\mathsf{False} \\Downarrow \\mathsf{False} }(B_2)\\\\ &\\dfrac{ x \\Downarrow \\mathsf{True} }{\\mathsf{Not} x\\Downarrow\\mathsf{False}}(B_3)\\quad &\\dfrac{ x \\Downarrow \\mathsf{False } }{\\mathsf{Not} x\\Downarrow \\mathsf{True}}(B_4)\\\\ &\\dfrac{ x \\Downarrow \\mathsf{False } }{\\mathsf{And} x y \\Downarrow \\mathsf{False}}(B_5)\\quad &\\dfrac{ x \\Downarrow \\mathsf{True} \\quad y \\Downarrow v }{\\mathsf{And} x y \\Downarrow v}(B_6) \\end{gather} $$ a) Show the evaluation of And (Not (And True False)) True with a derivation tree. (5 marks). \\[ \\dfrac {\\dfrac {\\dfrac {\\dfrac{}{True\\ \u21d3\\ True\\;}(B_5)\\ \\dfrac{}{False\\ \u21d3\\ False\\;}(B_6)} {(And\\ \\ True\\ False)\\ \u21d3\\ False}(B_4) } {(Not\\ \\ (And\\ \\ True\\ False))\\ \u21d3\\ True}(B_2) \\;\\dfrac{}{True\\ \u21d3\\ True\\;}(B_5) } {And\\ \\ (Not\\ \\ (And\\ \\ True\\ False))\\ \\ True\\ \u21d3\\ True}(B_4) \\] b) Consider the following inference rule: $$\\dfrac{y \u21d3 False} {And x y \u21d3 False} $$ If we assume that x B holds, is this rule derivable? Is it admissible? And if we don\u2019t assume that x B holds, how does this change your answers? Justify your answers. (5 marks) $$\\text{Assuming x B} $$ The inference rule R cannot be derived. This is because there is no way to construct a tree that looks like: $$\\dfrac{ \\dfrac{y \u21d3 False} {\\vdots } }{And x y \u21d3 False}\\; $$ However this rule is admissible, since it does not add strings to B. In this case if the result is used in the other inference rules, since x holds in B and y holds in B, that result will also hold in B. $$\\text{Not Assuming x B} $$ The inference rule R cannot be derived. This is because there is no way to construct a tree that looks like: $$\\dfrac{ \\dfrac{y \u21d3 False} {\\vdots } }{And x y \u21d3 False}\\; $$ This rule is not admissible with the current assumption, since it adds strings to B. This is because x does not hold in B, and if we use x in the other rules, we will get something is also not admissible in B.","title":"Part A (25 marks)"},{"location":"COMP3161/ass/Assignment%200/#_1","text":"","title":""},{"location":"COMP3161/ass/Assignment%200/#part-b-20-marks","text":"Here is a small-step semantics for a language L with True, False and if expressions: L:: True | False | If L then L else L $$ \\begin{gather} \\dfrac{ c \\mapsto c' }{(\\texttt{If} c t e) \\mapsto (\\texttt{If} c' t e) }&(1)\\\\ \\dfrac{ }{(\\texttt{If} \\texttt{True} t e) \\mapsto t }&(2)\\\\ \\dfrac{ }{(\\texttt{If} \\texttt{False} t e) \\mapsto e }&(3) \\end{gather} $$ 1. Show the full evaluation of the term (If True (If True False True) False). (5 marks) \\[ \\begin{align*} &\\text{(If True (If True False True) False)} \\\\ &\\mapsto \\text{If True False True (2)}\\\\ &\\mapsto \\text{False (2)} \\end{align*} \\] Define an equivalent big-step semantics for L. (5 marks) We define: A set of evaluable expressions T A set of values V A relation \u21d3 \u2286 E \u00d7 V T is the set of all closed expressions {t | t ok} and V is the set {True, False}. \\[ \\begin{gather} \\dfrac{}{\\text{$v$\\Downarrow $v$}}\\quad&(L_1)\\\\\\\\ \\dfrac{\\text{ $t_1 \\Downarrow$ True \\quad$t_2 \\Downarrow v_2$}}{\\text{(If $t_1$ then $t_2$ else $t_3 )\\Downarrow v_2$ }}&(L_2)\\\\\\\\ \\dfrac{ \\text{ $t_1 \\Downarrow$ False \\quad$t_3 \\Downarrow v_3$}}{\\text{(If $t_1$ then $t_2$ else $t_3 )\\Downarrow v_3$ }}&(L_3) \\end{gather} \\] 3. Prove that if \\(e \\Downarrow v\\) then \\(e \\stackrel{\\star}{\\mapsto} v\\) , where \\(\\Downarrow\\) is the big-step semantics you defined in the previous question, and \\(\\stackrel{\\star}{\\mapsto}\\) is the reflexive and transitive closure of \\(\\mapsto\\) . Use rule induction on \\(e \\Downarrow v\\) .","title":"Part B (20 marks)"},{"location":"COMP3161/ass/Assignment%200/#assumed-rules","text":"$$ \\dfrac{}{e \\stackrel{\\star}{\\mapsto} e}refl \\quad \\dfrac{e \\mapsto e' \\quad e' \\stackrel{\\star}{\\mapsto} e''} {e \\stackrel{\\star}{\\mapsto} e''}trans $$","title":"Assumed Rules"},{"location":"COMP3161/ass/Assignment%200/#if-e-downarrow-v-then-e-stackrelstarmapsto-v","text":"","title":"If \\(e \\Downarrow v\\) then \\(e \\stackrel{\\star}{\\mapsto} v\\)"},{"location":"COMP3161/ass/Assignment%200/#base-case-ev-from-a","text":"We must show that \\(v\\stackrel{\\star}{\\mapsto} v\\) , obvious by rule refl.","title":"Base Case \\((e=v)\\), from (A)"},{"location":"COMP3161/ass/Assignment%200/#inductive-case-e-if-t_1-then-t_2-else-t_3-from-b","text":"We know that \\(t_1 \\Downarrow True\\) and \\(t_2 \\Downarrow v_2\\) , which gives us the inductive hypotheses: - \\(IH_1 - t_1 \\stackrel{\\star}{\\mapsto} True\\) - \\(IH_2 - t_2 \\stackrel{\\star}{\\mapsto} v_2\\) Showing our overall goal: $$ \\begin{align*} \\text{(If \\(t_1\\) then \\(t_2\\) else \\(t_3\\) )} &\\stackrel{\\star}{\\mapsto}\\text{(If True then \\(t_2\\) else \\(t_3\\) )}&\\text{( \\(IH_1\\) with 1)}\\ &\\stackrel{\\star}{\\mapsto}t_2 &(2)\\ &\\stackrel{\\star}{\\mapsto}\\text{ \\(v_2\\) } &(IH_2)\\ \\end{align*} $$","title":"Inductive Case \\((e\\ =\\ (If\\ t_1\\ then\\ t_2\\ else\\ t_3))\\), from (B)"},{"location":"COMP3161/ass/Assignment%200/#inductive-case-e-if-t_1-then-t_2-else-t_3-from-c","text":"We know that \\(t_1 \\Downarrow False\\) and \\(t_3 \\Downarrow v_3\\) , which gives us the inductive hypotheses: - \\(IH_1 - t_1 \\stackrel{\\star}{\\mapsto} False\\) - \\(IH_2 - t_3 \\stackrel{\\star}{\\mapsto} v_3\\) Showing our overall goal: $$ \\begin{align*} \\text{(If \\(t_1\\) then \\(t_2\\) else \\(t_3\\) )} &\\stackrel{\\star}{\\mapsto}\\text{(If False then \\(t_2\\) else \\(t_3\\) )}&\\text{( \\(IH_1\\) with 1)}\\ &\\stackrel{\\star}{\\mapsto}t_3 &(3)\\ &\\stackrel{\\star}{\\mapsto}\\text{ \\(v_3\\) } &(IH_2)\\ \\end{align*} $$ Thus, by mathematical induction, we have shown one direction of the equivalence.","title":"Inductive Case \\((e\\ =\\ (If\\ t_1\\ then\\ t_2\\ else\\ t_3))\\), from (C)"},{"location":"COMP3161/ass/Assignment%200/#if-e-stackrelstarmapsto-v-then-e-downarrow-v","text":"Doing rule induction on the assumption \\(e \\stackrel{\\star}{\\mapsto} v\\) leads to two cases.","title":"If \\(e \\stackrel{\\star}{\\mapsto} v\\) then \\(e \\Downarrow v\\)"},{"location":"COMP3161/ass/Assignment%200/#base-case-ev-from-refl","text":"We know that \\(v \\Downarrow v\\) , from rule (A).","title":"Base case \\((e=v)\\), from refl"},{"location":"COMP3161/ass/Assignment%200/#inductive-case-ee-and-e-stackrelstarmapsto-v-from-trans","text":"We have the inductive hypothesis that \\(e'\\Downarrow v\\) , so it suffices to prove the following lemma in order to discharge this case. \\( \\(\\dfrac{s \\mapsto s'\\quad s' \\Downarrow v}{s \\Downarrow v}\\) \\)","title":"Inductive case (\\(e\u21a6e'\\) and \\(e \\stackrel{\\star}{\\mapsto} v\\)), from trans"},{"location":"COMP3161/ass/Assignment%200/#transitive-lemma-if-ee-and-ev-then-ev","text":"Written as a logical statement, this lemma is: \\( \\(\u2200v. (e\u21a6e')\u2227(e'\u21d3v)\u21d2e\u21d3v\\) \\) Equivalently, this can be stated as: \\( \\((e\u21a6e')\u21d2(\u2200v. e\u2032\u21d3v)\u21d2(e\u21d3v)\\) \\) This formulation lets us proceed by rule induction on the assumption \\(e\u21a6e'\\) , proving for each case for any arbitrary v: \\( \\(\u2200v. \\dfrac{e'\u21d3v}{e\u21d3v}\\) \\)","title":"Transitive Lemma: If \\(e\u21a6e'\\) and \\(e'\u21d3v\\) then \\(e\u21d3v\\)"},{"location":"COMP3161/ass/Assignment%200/#base-case-1-from-rule-2","text":"Here \\(e = \\text{(If True t e)}\\) and \\(e' = t\\) . We have to show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . The only way that assumption could hold, looking at the rules of \u21d3, is if \\(v = t\\) from rule A. Therefore we must show that \\((\\text{If True t e}) \u21d3 t\\) , which is trivial from A and B.","title":"Base Case 1, from rule (2)"},{"location":"COMP3161/ass/Assignment%200/#base-case-2-from-rule-3","text":"Here \\(e = \\text{(If False t e)}\\) and \\(e' = \\text{e}\\) . We have to show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . The only way that assumption could hold, looking at the rules of \u21d3, is if \\(v =\\text{e}\\) from rule A. Therefore we must show that \\(\\text{(If True t e) \u21d3 e}\\) , which is trivial from A and B.","title":"Base Case 2, from rule (3)"},{"location":"COMP3161/ass/Assignment%200/#inductive-case-from-rule-1","text":"Here \\(e = \\text{(If c t e)}\\) and \\(e' = \\text{(If c}'\\text{ t e)}\\) . We know that \\(c\u21a6c'\\) , giving the inductive hypothesis that: \\[\u2200v. \\dfrac{c'\u21d3v}{c\u21d3v}IH\\] We must show that \\(e \u21d3 v\\) assuming that \\(e' \u21d3 v\\) . Looking at the rules for \u21d3, the only way that \\(e' \u21d3 v\\) could hold is if there is some \\(v_x\\) such that \\(\\text{c}'\u21d3v_x\\) and \\(\\text{t} \u21d3 v_t\\) and \\(\\text{e} \u21d3 v_e\\) . (which can be proven by rule B and C). Hence by the inductive hypothesis, we have that \\(c\u21d3v_x\\) . Therefore, \\(e \u21d3 v\\) as required.","title":"Inductive Case, from rule (1)"},{"location":"COMP3161/ass/Assignment%200/#_2","text":"","title":""},{"location":"COMP3161/ass/Assignment%200/#part-c-15-marks","text":"Define a recursive compilation function \\(c : B \u2192 L\\) which converts expressions in \\(B\\) to expressions in \\(L\\) . (5 marks) \\[\\begin{align} c(\\textsf{Not} \\; x) &= \\text{If\\ $c(x)$\\ then\\ False\\ else\\ True}&(C_1)\\\\\\\\ c(\\textsf{And} \\; x \\; y) &= \\text{If $c(x)$ then $c(y)$ else False}&(C_2)\\\\\\\\ c(\\textsf{True}) &= True&(C_3)\\\\\\\\ c(\\textsf{False}) &= False&(C_4) \\end{align} \\] Prove that for all \\(e, e \u21d3 v\\) implies \\(c(e) \u21d3 v\\) , by rule induction on the assumption that \\(e \u21d3 v\\) . (10 marks) For all proofs of induction, I have abbreviated \\(True \\implies \\mathsf{T}\\ and\\ False \\implies \\mathsf{F}\\) .","title":"Part C (15 marks)"},{"location":"COMP3161/ass/Assignment%200/#rule-1","text":"From (1), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{F}\\) and the assumption \\(x \\Downarrow \\mathsf{T}\\) . Hence the statement above we conclude our inductive hypothesis: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{T}&\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{Not}\\ x)=\\mathsf{F}\\) . $$ \\begin{align*} \\dfrac{\\dfrac{}{c(x)\\Downarrow \\mathsf{T}}(I.H.)\\quad\\dfrac{}{\\mathsf{F}\\Downarrow \\mathsf{F}}(B_6)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(\\mathsf{F}\\) else \\(\\mathsf{T}\\) ) \\(\\Downarrow \\mathsf{F}\\) }} { c(\\mathsf{Not} x) \\Downarrow \\mathsf{F} }(C_1) }(L_2) \\end{align*} $$","title":"Rule (1)"},{"location":"COMP3161/ass/Assignment%200/#rule-2","text":"From (2), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{T}\\) and the assumption \\(x \\Downarrow \\mathsf{F}\\) . Hence the statement above we conclude our inductive hypothesis: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{F}&\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{Not}\\ x)=\\mathsf{T}\\) . $$ \\begin{align*} \\dfrac{\\dfrac{}{c(x)\\Downarrow \\mathsf{F}}(I.H.)\\quad\\dfrac{}{\\mathsf{T}\\Downarrow \\mathsf{T}}(B_5)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(\\mathsf{F}\\) else \\(\\mathsf{T}\\) ) \\(\\Downarrow \\mathsf{T}\\) }} { c(\\mathsf{Not} x) \\Downarrow \\mathsf{T} }(C_1) }(L_2) \\end{align*} $$","title":"Rule (2)"},{"location":"COMP3161/ass/Assignment%200/#rule-3","text":"From (3), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{F}\\) and the assumption \\(x \\Downarrow \\mathsf{F}\\) . Hence the statement above we conclude our inductive hypotheses: $$ \\begin{align } c(x)&\\Downarrow\\mathsf{F} &\\quad(I.H.) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{And}\\ x\\ y)=\\mathsf{F}\\) . $$ \\begin{align*} \\dfrac{ \\dfrac{}{c(x)\\Downarrow \\mathsf{F}}(I.H_1)\\quad \\dfrac{}{\\mathsf{F}\\Downarrow \\mathsf{F}}(B_6)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(c(y)\\) else \\(\\mathsf{F}\\) ) \\(\\Downarrow \\mathsf{F}\\) }} { c(\\mathsf{And} x y) \\Downarrow \\mathsf{F} }(C_2) }(L_3) \\end{align*} $$","title":"Rule (3)"},{"location":"COMP3161/ass/Assignment%200/#rule-4","text":"For this proof, I have renamed the value \\(v\\) from the rule, as \\(\\mathsf{v_k}\\) . From (4), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{v_k}\\) and the assumptions \\(x \\Downarrow \\mathsf{T}\\) and \\(y \\Downarrow \\mathsf{v_k}\\) . Hence the statement above we conclude our inductive hypotheses: $$ \\begin{align } c(x)&\\Downarrow \\mathsf{T} &\\quad(I.H_1) \\ \\ c(y)&\\Downarrow \\mathsf{v_k} &\\quad(I.H_2) \\end{align } $$ We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{And}\\ x\\ y)=\\mathsf{v_k}\\) . $$ \\begin{align*} \\dfrac{ \\dfrac{}{c(x)\\Downarrow \\mathsf{T}}(I.H_1)\\quad \\dfrac{}{c(y)\\Downarrow \\mathsf{v_k}}(I.H_2)} { \\dfrac{\\text{(If \\(c(x)\\) then \\(c(y)\\) else \\(\\mathsf{F}\\) ) \\(\\Downarrow \\mathsf{v_k}\\) }} { c(\\mathsf{And} x y) \\Downarrow \\mathsf{v_k} }(C_2) }(L_2) \\end{align*} $$","title":"Rule (4)"},{"location":"COMP3161/ass/Assignment%200/#rule-5","text":"From (5), we declare \\(e = \\mathsf{T}\\) , \\(v = \\mathsf{T}\\) . We can now prove that \\(c(e) \\Downarrow v\\) , or in other words \\(c(\\mathsf{T}) \\Downarrow \\mathsf{T}\\) . \\[ \\dfrac{}{\\dfrac{T \\Downarrow T}{c(T) \\Downarrow T}} $$ ### Rule (6) From (6), we declare $e = \\mathsf{F}$, $v = \\mathsf{F}$. We can now prove that $c(e) \\Downarrow v$, or in other words $c(e) \\Downarrow \\mathsf{F}$. $$ \\dfrac{}{\\dfrac{F \\Downarrow F}{c(F) \\Downarrow F}} \\]","title":"Rule (5)"},{"location":"COMP3161/ass/Assignment%200/#_3","text":"","title":""},{"location":"COMP3161/ass/Assignment%200/#part-d","text":"Here is a term in \\(\\lambda\\) -calculus: $$ (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) $$ a) Fully \u03b2-reduce the above \u03bb-term. Show all intermediate beta reduction steps. (5 marks) $$ \\begin{align } (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) &\\mapsto_\\beta\\lambda f. \\lambda x. ((\\lambda f. \\lambda x. f x) f (f x))&\\text{[On \\(n\\) ]}\\ &\\equiv_\\alpha\\lambda f. \\lambda x. ((\\lambda f'. \\lambda x'. f' x') f (f x))&\\text{[ \\(f\\mapsto\\ f'\\) , \\(x\\mapsto\\ x'\\) ]}\\ &\\mapsto_\\beta\\lambda f. \\lambda x. (( \\lambda x'. f x' ) (f x))\\quad&\\text{[On \\(f'\\) ]}\\ &\\mapsto_\\beta\\lambda f. \\lambda x. f (f x)\\quad \\blacksquare &\\text{[On \\(x'\\) ]} \\end{align } $$ b) Identify an \u03b7-reducible expression in the above (unreduced) term. (5 marks) We can reduce the unreduced expression using \\(\\eta\\) -reduction on \\(x\\) . $$ \\begin{align } (\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. \\lambda x. f x) &\\mapsto_\\eta(\\lambda n. \\lambda f. \\lambda x. (n f (f x))) (\\lambda f. f) \\end{align } $$","title":"Part D."},{"location":"COMP3161/ass/Assignment%200/#for-question-2-and-3-i-will-shorthand-x-y-x-implies-mathbft-and-x-y-y-implies-mathbff","text":"Recall that in \u03bb-calculus, booleans can be encoded as binary functions that return one of their arguments: \\( \\(\\begin{align*}\\mathbf{T} \u2261 (\u03bbx. \u03bby. x)\\\\ \\mathbf{F} \u2261 (\u03bbx. \u03bby. y) \\end{align*}\\) \\) Either via L or directly, define a function d : B \u2192 \u03bb which converts expressions in B to \u03bb-calculus. (5 marks) \\[\\begin{align*} d(\\textsf{Not} \\; x) &= (\\lambda x. x\\ \\mathbf{F}\\ \\mathbf{T})\\ d(x)&(D_1)\\\\\\\\ d(\\textsf{And} \\; x \\; y) &= (\\lambda a. \\lambda b.\\ a\\ b\\ a)\\ d(x)\\ d(y)&(D_2)\\\\\\\\ d(\\textsf{True}) &= \\mathbf{T}&(D_3)\\\\\\\\ d(\\textsf{False}) &= \\mathbf{F}&(D_4) \\end{align*} \\] Prove that for all e such that \\(e \u21d3 v\\) it holds that \\(d (e) \\equiv_{\\alpha\\beta\\eta} v'\\) , where \\(v'\\) is the \u03bb-calculus encoding of v.","title":"For question 2 and 3, I will shorthand \\((\u03bbx. \u03bby. x) \\implies \\mathbf{T}\\) and \\((\u03bbx. \u03bby. y) \\implies \\mathbf{F}\\)."},{"location":"COMP3161/ass/Assignment%200/#rule-1_1","text":"From (1), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{False}\\) and the assumptions \\(x \\Downarrow \\mathsf{True}\\) . From the statement above we have our inductive hypothesis: $$ \\begin{align } d(x)&=d(True)&\\ &=\\mathbf{T}&(I.H.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(False)\\\\ &=\\mathbf{F} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{Not} \\ x) \\equiv_{\\alpha\\beta\\eta} \\mathsf{F}\\) .A $$ \\begin{align } d(\\mathsf{Not} x) &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) d(x)&(D_1)\\ &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) \\mathbf{T} &(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} \\mathbf{F} \\mathsf{T}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} &\\blacksquare\\ \\end{align } $$","title":"Rule (1)"},{"location":"COMP3161/ass/Assignment%200/#rule-2_1","text":"From (2), we declare \\(e =\\mathsf{Not}\\ x\\) , \\(v = \\mathsf{True}\\) and the assumptions \\(x \\Downarrow \\mathsf{False}\\) . From the statement above we have our inductive hypothesis: $$ \\begin{align } d(x)&=d(False)&\\ &=\\mathbf{F}&(I.H.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(True)\\\\ &=\\mathbf{T} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{Not} \\ x) \\equiv_{\\alpha\\beta\\eta} \\mathsf{T}\\) . $$ \\begin{align } d(\\mathsf{Not} x) &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) d(x)&(D_1)\\ &=(\\lambda x. x \\mathbf{F} \\mathbf{T}) \\mathbf{F} &(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} \\mathbf{F} \\mathsf{T}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} &\\blacksquare\\ \\end{align } $$","title":"Rule (2)"},{"location":"COMP3161/ass/Assignment%200/#rule-3_1","text":"From (3), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathsf{False}\\) and the assumptions \\(x \\Downarrow \\mathsf{False}\\) . From the statement above we have our inductive hypotheses: $$ \\begin{align } d(x)&=d(False)&\\ &=\\mathbf{F}&(I.H.)\\\\ \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(v)&\\\\ &=d(False)\\\\ &=\\mathbf{F} \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{And} \\ x\\ y) \\equiv_{\\alpha\\beta\\eta} \\mathsf{F}\\) . $$ \\begin{align } d(\\mathsf{And} x y) &=(\\lambda a. \\lambda b. a b a) d(x) d(y)&(D_2)\\ &=(\\lambda a. \\lambda b. a b a) \\mathbf{F} d(y)&(From I.H)\\ &\\equiv_{\\alpha\\beta\\eta}(\\lambda b \\mathbf{F} b \\mathsf{F}) d(y)\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} d(y) \\mathbf{F}\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{F} &\\blacksquare\\ \\end{align } $$","title":"Rule (3)"},{"location":"COMP3161/ass/Assignment%200/#rule-4_1","text":"For this proof, I have renamed the value \\(v\\) from the rule, as \\(\\mathbf{v_k}\\) . From (4), we declare \\(e =\\mathsf{And}\\ x\\ y\\) , \\(v = \\mathbf{v_k}\\) and the assumptions \\(x \\Downarrow \\mathsf{True}\\) and \\(y \\Downarrow \\mathbf{v_k}\\) . From the statement above we have our inductive hypotheses: $$ \\begin{align } d(x)&=d(True)&\\ &=\\mathbf{T}&(I.H_1.)\\\\ d(y)&=d(\\mathbf{v_k})&(I.H_2.) \\end{align } $$ We also compute \\(v'\\) \\[ \\begin{align*} v'&=d(\\mathbf{v_k})&\\\\ \\end{align*} \\] We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{And} \\ x\\ y) \\equiv_{\\alpha\\beta\\eta} d(\\mathbf{v_k})\\) . $$ \\begin{align } d(\\mathsf{And} x y) &=(\\lambda a. \\lambda b. a b a) d(x) d(y)&(D_2)\\ &=(\\lambda a. \\lambda b. a b a) \\mathbf{T} d(\\mathbf{v_k})&(From I.H_1 and I.H_2.)\\ &\\equiv_{\\alpha\\beta\\eta}(\\lambda b \\mathbf{T} b \\mathbf{T}) d(\\mathbf{v_k})\\ &\\equiv_{\\alpha\\beta\\eta}\\mathbf{T} d(\\mathbf{v_k}) \\mathbf{T}\\ &\\equiv_{\\alpha\\beta\\eta}d(\\mathbf{v_k}) &\\blacksquare\\ \\end{align } $$","title":"Rule (4)"},{"location":"COMP3161/ass/Assignment%200/#rule-5_1","text":"From (5), we declare \\(e = True\\) and \\(v=True\\) . We also compute \\(v'\\) $$ \\begin{align } v'&=d(True)\\ &=\\mathbf{T} \\end{align } $$ We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{True} ) \\equiv_{\\alpha\\beta\\eta} \\mathbf{T}\\) . $$ \\begin{align} d(True) &\\equiv_{\\alpha\\beta\\eta} \\mathbf{T} &(D_3) \\end{align} $$","title":"Rule (5)"},{"location":"COMP3161/ass/Assignment%200/#rule-6","text":"From (6), we declare \\(e = False\\) and \\(v=False\\) . We also compute \\(v'\\) $$ \\begin{align } v'&=d(False)\\ &=\\mathbf{F} &(D_4) \\end{align } $$ We can now prove that \\(d(e) \\equiv_{\\alpha\\beta\\eta} v'\\) , or in other words \\(d(\\mathsf{False} ) \\equiv_{\\alpha\\beta\\eta} \\mathbf{F}\\) . $$ \\begin{align} d(False) &\\equiv_{\\alpha\\beta\\eta} \\mathbf{F} &(D_3) \\end{align} $$ Suppose we added unary local function definitions to our language \\(\\mathcal{P}\\) . Here's an example in concrete syntax: $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{g}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{g}(\\mathsf{True})\\ \\mathsf{end} \\end{array} $$ We limit ourselves to non-recursive bindings (meaning functions can't call themselves), and first-order functions (meaning functions require boolean arguments). a) Extend the abstract syntax for \\(\\mathcal{B}\\) from question A.3 so that it supports the features used in the above example. Use first-order abstract syntax with explicit strings. You don't have to extend the parsing relation. (5 marks) We extend B to $$ \\begin{align} B ::&= &\\mathsf{True}\\ &| &\\mathsf{False}\\ &| &\\mathsf{Not B}\\ &| &\\mathsf{And B B}\\ &| &\\mathsf{Func F B}\\ &| &\\mathsf{Var M}\\ &| &\\mathsf{Let F B B in B End} \\end{align} $$ For my additions: Func F B takes in two arguments, F is the function name and B is the variable. Var M takes in one argument, where M is a variable. Let F B B B takes in four arguments, F is the name of the function, the first B is the assigned variable for F, the second B is the replacement expression, and the third B is the expression we apply the function. An example is Let \"g\" (Var \"x\") (Not \"x\") (F \"g\" True) b) Define a scope-checking judgement, similar to the \\(\\mathbf{ok}\\) judgement from the lectures. It should check (a) that all names of variables and functions are used only within their scopes; and (b) that names used in variable (or function) position are indeed the names of variables (or functions). Hence, the following expressions should both be rejected: $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathit{x})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\neg\\mathit{x} \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathit{f})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{x}(\\mathsf{True}) \\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathsf{False})\\ \\mathsf{end} \\end{array} $$ The following are examples of things that should be accepted: nullary definitions, nested definitions, and shadowed definitions. $$ \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) =\\ \\quad\\mathsf{let} \\ \\quad\\;\\;\\mathit{g}(\\mathit{y}) = \\neg\\mathit{x}\\wedge\\mathit{y} \\ \\quad\\mathsf{in} \\ \\quad\\;\\; \\mathit{g}(\\mathit{x}) \\wedge \\neg\\mathit{g}(\\mathit{x})\\ \\quad\\mathsf{end}\\ \\mathsf{in} \\ \\;\\; \\mathit{f}(\\mathsf{False})\\ \\mathsf{end} \\end{array} \\quad \\begin{array}{l} \\mathsf{let} \\ \\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{x}(\\mathsf{True}) \\ \\mathsf{in} \\ \\quad\\mathsf{let} \\ \\quad\\;\\;\\mathit{f}(\\mathit{x}) = \\mathit{f}(\\mathit{x}) \\ \\quad\\mathsf{in} \\ \\quad\\;\\; \\mathit{f}(\\mathsf{True})\\ \\quad\\mathsf{end}\\ \\mathsf{end} \\end{array} $$ Note that the latter example is not a recursive call. (10 marks) It should check (a) that all names of variables and functions are used only within their scopes (b) that names used in variable (or function) position are indeed the names of variables (or functions). $$ \\begin{gather} &\\dfrac{}{\\Gamma \\vdash True \\mathbf{ok}}\\\\ &\\dfrac{}{\\Gamma \\vdash False \\mathbf{ok}}\\\\ &\\dfrac{\\Gamma \\vdash e_1 \\mathbf{ok}}{\\Gamma \\vdash \\mathsf{Not} (e_1) \\mathbf{ok}}\\\\ &\\dfrac{\\Gamma \\vdash e_1 \\mathbf{ok}\\quad\\Gamma \\vdash e_2 \\mathbf{ok}}{\\Gamma \\vdash \\mathsf{And} (e_1 e_2) \\mathbf{ok}}\\\\ &\\dfrac{(x bound)\\in\\Gamma}{\\Gamma \\vdash (Var x) \\mathbf{ok}}\\\\ &\\dfrac{(f bound)\\in\\Gamma\\quad\\Gamma\\vdash e_1 \\mathbf{ok}}{\\Gamma \\vdash (Func f e_1) \\mathbf{ok}}\\\\ &\\dfrac{(x bound), \\Gamma\\vdash e_1\\quad(f bound) ,\\Gamma\\vdash e_2 \\mathbf{ok}}{\\Gamma \\vdash (Let f x e_1 e_2) \\mathbf{ok}}\\\\ \\end{gather} $$","title":"Rule (6)"},{"location":"COMP3161/wk1/Lecture%201/","text":"What are types - abstraction (provides an interface) - static analysis - analyses the logic of the program Should we have a type system in the first place ? Tut 1 Question ? Types let you avoid type errors How do you know that the type system avoids type errors? Let us consider the following Java Code class Shape{} class Rectangle extends Shape {} class Triangle extends Shape {} And then lets try to convert a Rectangle to a Triangle. ... public class Hello { public static Trinagle Rectangle2Triangle(Rectangle rect) { return ret; } } Two possibilties: 1. The program runs without an error 2. We get some kind of runtime error Whichever happens we get a violation of a mathematical proerty of type system. 1. subject reduction (if i have a well-typed program, that does not do tpye cast, it stays well-typed) 2. progress (the behaviour of every well typed program is well-defined) Course Content We do 3 R's Read and understand new programming languages Write your own programming languages Reason about programming languages in a rigorous way Read: - Language researchers create new ones - Formal verification as proof ![[Pasted image 20220913170120.png]]","title":"Lecture 1"},{"location":"COMP3161/wk1/Tut%201%20Haskell/","text":"Haskell lexical structure \u00b6 What is the difference between a data and a type declaration? Data is an enumerated list of types, where you can include algebraic data types. A type is a declaration of kind. 'String', \"Char\", \"Int\" data List a = Nil | Cons a (List a) type IntList = List Int What is the difference between a type and a data constructor ? List the identifiers in the code which represent type names , and those which represent data constructor names . Which phase of the compiler would be responsible for distinguishing type and data constructors? Haskell programming \u00b6 Write a Haskell function mySum that sums all elements in a list of numbers. Feel free to use the following template: haskell mySum :: [Int] -> Int mySum [] = ??? mySum (n:ns) = ??? mySum :: [Int] -> Int mySum [] = 0 mySum (n:ns) = n + mySum ns Write a Haskell function myProduct that multiplies all elements in a list of numbers. myProduct :: [Int] -> Int myProduct [] = 1 myProduct (n:ns) = n * mySum ns myProduct2 :: [Int] -> Int myProduct2 [] = 0 myProduct2 [x] = x myProduct2 (n:ns) = n * mySum ns myProduct3 :: [Int] -> Int myProduct2 xs = foldr (*) 1 xs You probably used copypaste to solve the previous question, didn't you? No reason to be ashamed, we've all done it! But let's try not to. Find a generalisation myBinop that applies a given binary operator f with unit element z to a list of numbers. We will then be able to define myProduct and mySum using myBinop . ```haskell myBinop :: (Int -> Int -> Int) -> Int -> ([Int] -> Int) myBinop f z [] = ??? myBinop f z (n:ns) = ??? mySum :: [Int] -> Int mySum ns = myBinop (+) 0 ns myProduct :: [Int] -> Int myProduct ns = myProduct (*) 1 ns ``` myBinop :: (Int -> Int -> Int) -> Int -> ([Int] -> Int) myBinop f z [] = z myBinop f z (n:ns) = myBinop f (f z n) (ns) myBinop2 = foldr mySum :: [Int] -> Int mySum ns = myBinop (+) 0 ns myProduct :: [Int] -> Int myProduct ns = myBinop (*) 1 ns We just reinvented a wheel. The fold functions are general-purpose library functions that completely subsume myBinop . Try to implement mySum and myProduct using foldr instead of myBinop . The linked library documentation references a lot of concepts that we don't assume familiarity with, so don't worry if you don't fully understand it. Perhaps start by looking at the examples. mySum :: [Int] -> Int mySum ns = foldr (+) 0 ns myProduct :: [Int] -> Int myProduct [] = 0 myProduct ns = foldr (*) 1 ns Subtyping Sins \u00b6 The Monday lecture Lecture 1 demonstrated a flaw in Java's static type system. It's been there for decades and it's well-known, including by the Java developers. Yet they've chosen not to fix it. Why do you think that is?","title":"Tut 1 Haskell"},{"location":"COMP3161/wk1/Tut%201%20Haskell/#haskell-lexical-structure","text":"What is the difference between a data and a type declaration? Data is an enumerated list of types, where you can include algebraic data types. A type is a declaration of kind. 'String', \"Char\", \"Int\" data List a = Nil | Cons a (List a) type IntList = List Int What is the difference between a type and a data constructor ? List the identifiers in the code which represent type names , and those which represent data constructor names . Which phase of the compiler would be responsible for distinguishing type and data constructors?","title":"Haskell lexical structure"},{"location":"COMP3161/wk1/Tut%201%20Haskell/#haskell-programming","text":"Write a Haskell function mySum that sums all elements in a list of numbers. Feel free to use the following template: haskell mySum :: [Int] -> Int mySum [] = ??? mySum (n:ns) = ??? mySum :: [Int] -> Int mySum [] = 0 mySum (n:ns) = n + mySum ns Write a Haskell function myProduct that multiplies all elements in a list of numbers. myProduct :: [Int] -> Int myProduct [] = 1 myProduct (n:ns) = n * mySum ns myProduct2 :: [Int] -> Int myProduct2 [] = 0 myProduct2 [x] = x myProduct2 (n:ns) = n * mySum ns myProduct3 :: [Int] -> Int myProduct2 xs = foldr (*) 1 xs You probably used copypaste to solve the previous question, didn't you? No reason to be ashamed, we've all done it! But let's try not to. Find a generalisation myBinop that applies a given binary operator f with unit element z to a list of numbers. We will then be able to define myProduct and mySum using myBinop . ```haskell myBinop :: (Int -> Int -> Int) -> Int -> ([Int] -> Int) myBinop f z [] = ??? myBinop f z (n:ns) = ??? mySum :: [Int] -> Int mySum ns = myBinop (+) 0 ns myProduct :: [Int] -> Int myProduct ns = myProduct (*) 1 ns ``` myBinop :: (Int -> Int -> Int) -> Int -> ([Int] -> Int) myBinop f z [] = z myBinop f z (n:ns) = myBinop f (f z n) (ns) myBinop2 = foldr mySum :: [Int] -> Int mySum ns = myBinop (+) 0 ns myProduct :: [Int] -> Int myProduct ns = myBinop (*) 1 ns We just reinvented a wheel. The fold functions are general-purpose library functions that completely subsume myBinop . Try to implement mySum and myProduct using foldr instead of myBinop . The linked library documentation references a lot of concepts that we don't assume familiarity with, so don't worry if you don't fully understand it. Perhaps start by looking at the examples. mySum :: [Int] -> Int mySum ns = foldr (+) 0 ns myProduct :: [Int] -> Int myProduct [] = 0 myProduct ns = foldr (*) 1 ns","title":"Haskell programming"},{"location":"COMP3161/wk1/Tut%201%20Haskell/#subtyping-sins","text":"The Monday lecture Lecture 1 demonstrated a flaw in Java's static type system. It's been there for decades and it's well-known, including by the Java developers. Yet they've chosen not to fix it. Why do you think that is?","title":"Subtyping Sins"},{"location":"COMP3161/wk1/Tut%201/","text":"Predicate Logic \u00b6 Question 1 \u00b6 For which values of A and B does the boolean expression \u03c6=\u00ac(A\u21d2B)\u2228\u00acB hold? (a ^ ~b) V ~b ~b V ~b ~b Question 2 \u00b6 Simplify the boolean expression (A\u21d2B)\u2228(B\u21d2A) (~a V b) V (~b V a) a V ~a V b V ~b T V T T ~b V b = T is not generally ok it corresponds to a function constructive logic Question 3 \u00b6 A binary connective \u2219 is defined as follows: A B A \u2219 B \u22a5 \u22a5 \u22a4 \u22a5 \u22a4 \u22a5 \u22a4 \u22a5 \u22a4 \u22a4 \u22a4 \u22a4 Restate the formula A\u2228B in terms of \u2219. What is the \u2219 connective? The \u2219 connective is B -> A. Question 4 \u00b6 Assuming that F(x) states that the person x is my friend and that P(x) states that the person x is perfect, what is a logical translation of the phrase \"None of my friends are perfect\"? All of my friends are not perfect. Or If you are my friend, you are not perfect. \u2200x F(x) -> ~ P(x) Question 5 \u00b6 Given the following function f(n) 0 n=0 2n\u22121+f(n\u22121) n>0 Prove that \u2200n\u2208N. f(n)=n^2. f(0) = 0 = 0^2 So true for f(0). Assume true for f(k). Hypo: f(k) = k^2. rtp: true for f(k+1) f(k+1) = 2(k+1) - 1 + f(k) = 2k + 1 + f(k) = k^2 + 2k + 1 = (k+1)^2","title":"Tut 1"},{"location":"COMP3161/wk1/Tut%201/#predicate-logic","text":"","title":"Predicate Logic"},{"location":"COMP3161/wk1/Tut%201/#question-1","text":"For which values of A and B does the boolean expression \u03c6=\u00ac(A\u21d2B)\u2228\u00acB hold? (a ^ ~b) V ~b ~b V ~b ~b","title":"Question 1"},{"location":"COMP3161/wk1/Tut%201/#question-2","text":"Simplify the boolean expression (A\u21d2B)\u2228(B\u21d2A) (~a V b) V (~b V a) a V ~a V b V ~b T V T T ~b V b = T is not generally ok it corresponds to a function constructive logic","title":"Question 2"},{"location":"COMP3161/wk1/Tut%201/#question-3","text":"A binary connective \u2219 is defined as follows: A B A \u2219 B \u22a5 \u22a5 \u22a4 \u22a5 \u22a4 \u22a5 \u22a4 \u22a5 \u22a4 \u22a4 \u22a4 \u22a4 Restate the formula A\u2228B in terms of \u2219. What is the \u2219 connective? The \u2219 connective is B -> A.","title":"Question 3"},{"location":"COMP3161/wk1/Tut%201/#question-4","text":"Assuming that F(x) states that the person x is my friend and that P(x) states that the person x is perfect, what is a logical translation of the phrase \"None of my friends are perfect\"? All of my friends are not perfect. Or If you are my friend, you are not perfect. \u2200x F(x) -> ~ P(x)","title":"Question 4"},{"location":"COMP3161/wk1/Tut%201/#question-5","text":"Given the following function f(n) 0 n=0 2n\u22121+f(n\u22121) n>0 Prove that \u2200n\u2208N. f(n)=n^2. f(0) = 0 = 0^2 So true for f(0). Assume true for f(k). Hypo: f(k) = k^2. rtp: true for f(k+1) f(k+1) = 2(k+1) - 1 + f(k) = 2k + 1 + f(k) = k^2 + 2k + 1 = (k+1)^2","title":"Question 5"},{"location":"COMP3161/wk10/Abstract%20Data%20Types/","text":"Most info recieved from https://lukakerr.github.io/uni/3161-notes#abstract-data-types Bag ADT Example \u00b6 Specified by three operations emptyBag - BB addToBag - (B\u2192Int\u2192B)(B\u2192Int\u2192B) average - (B\u00d7Int)(B\u00d7Int) in this case we think, it cannot be forall, since its impossible so we write the type as a product of all possible types from the functions. The type for this ADT is \u2203B.B\u00d7(B\u2192Int\u2192B)\u00d7(B\u2192Int)\u2203B.B\u00d7(B\u2192Int\u2192B)\u00d7(B\u2192Int)","title":"Abstract Data Types"},{"location":"COMP3161/wk10/Abstract%20Data%20Types/#bag-adt-example","text":"Specified by three operations emptyBag - BB addToBag - (B\u2192Int\u2192B)(B\u2192Int\u2192B) average - (B\u00d7Int)(B\u00d7Int) in this case we think, it cannot be forall, since its impossible so we write the type as a product of all possible types from the functions. The type for this ADT is \u2203B.B\u00d7(B\u2192Int\u2192B)\u00d7(B\u2192Int)\u2203B.B\u00d7(B\u2192Int\u2192B)\u00d7(B\u2192Int)","title":"Bag ADT Example"},{"location":"COMP3161/wk10/tut/","text":"Overloading \u00b6 Problems with writing custom comparators for multiple classes We want to abstract classes so we have a common comparator Known as typeclasses, or traits in rust, extends class in java. -- there exists a partial ordering on 'a' class Compare a where cmp :: a -> a -> Bool -- real implementation of compare (extending Compare a) instance Compare Int where cmp x y = x <= y -- we want to compare a list of elements instance (Compare a) => Compare [a] where cmp xs ys = and (zipWith cmp xs ys) -- we wish to compare a list of lists group :: (Compare a) => [a] -> [[a]] group [] = [] group (x:xs) = let (ys, zs) = span (cmp x) xs in (x:ys) : group zs Haskell will convert the class into a type. type CompareDict a = (a -> a -> Bool) instances get turned into functions or values. instance Compare Int where cmp x y = x <= y intCompDict :: CompareDict Int intCompDict = (\\x y -> x <= y) -- we want to compare a list of elements instance (Compare a) => Compare [a] where cmp xs ys = and (zipWith cmp xs ys) listCmpD :: CompareDict a -> Compare [a] cmp xs ys = and (zipWith cmp xs ys) -- we wish to compare a list of lists group :: (Compare a) => [a] -> [[a]] group [] = [] group (x:xs) = let (ys, zs) = span (cmp x) xs in (x:ys) : group zs SubTyping \u00b6 Coercions and Subtyping \u00b6 You are given the type Rectangle , parameterised by its height and width, and the type Square parameterised by the length of one of its sides. Neither type is mutable. a. Which type is the subtype, which type is the supertype? Subtype: Square SuperType: Rectangle b. Give a subtype/supertype ordering of the following set of function types: Rectangle -> Rectangle , Rectangle -> Square , Square -> Rectangle , Square -> Square . graphBT; SqRect --> RectRect; Rect -> Sq ==> Sq -> Rect Any values in p1 -> p2 must exist in t1 -> t2. Fix the return type, a c. Define a data type Square and a data type Rectangle in Haskell. Then define a coercion function from elements of the subclass to elements of the superclass. We first decide whether we change the input of the function, or change the output of the function. d. Show that the ordering you have given in the previous question is correct by defining coercion functions for each pair of types in a subtyping relationship in part (b). Constructor variance \u00b6 List some examples of a covariant , contravariant and invariant type constructor. LCR Conditions \u00b6 Consider the following two processes, each manipulating a shared variable x, which starts out at 0. Thread 1 : x:=x+1;x:=x\u22121; Thread 2 : x:=x\u00d72 a) What are the possible final values of x assuming each statement is executed atomically ? 0, 1. b) Rewrite the above program into one where each statement obeys the limited critical reference restriction. What are the possible final values now? -1, 0, 1, 2 c) How could locks be used in your answer to (b) to ensure that only the final results from part (a) are possible? var t; take(l); t := x; x := t + 1; release(l); take(l); t := x; x := t - 1; release(l); var u; take(l); u :=x; x:= u * 2; release(l); After p2, wantp is set to 1 or -1, or abs val is 1. After q2, wantq is set to 1 or -1, or abs bal is 1. in other for both critical sectios to be passed, we must have both await clauses to be true. wantp != wantq, and wantp != -wantq. if both are set to 1 it could run both, we run p2 and q2 at the same time, however we assign only one of them i.e. wantq = -1. then run q3, and pass into the critical section infinitely. then we assign p2. wantp = 1 we check the statement wantp != wantq (1 != -1) which passes into the critical section.","title":"Tut"},{"location":"COMP3161/wk10/tut/#overloading","text":"Problems with writing custom comparators for multiple classes We want to abstract classes so we have a common comparator Known as typeclasses, or traits in rust, extends class in java. -- there exists a partial ordering on 'a' class Compare a where cmp :: a -> a -> Bool -- real implementation of compare (extending Compare a) instance Compare Int where cmp x y = x <= y -- we want to compare a list of elements instance (Compare a) => Compare [a] where cmp xs ys = and (zipWith cmp xs ys) -- we wish to compare a list of lists group :: (Compare a) => [a] -> [[a]] group [] = [] group (x:xs) = let (ys, zs) = span (cmp x) xs in (x:ys) : group zs Haskell will convert the class into a type. type CompareDict a = (a -> a -> Bool) instances get turned into functions or values. instance Compare Int where cmp x y = x <= y intCompDict :: CompareDict Int intCompDict = (\\x y -> x <= y) -- we want to compare a list of elements instance (Compare a) => Compare [a] where cmp xs ys = and (zipWith cmp xs ys) listCmpD :: CompareDict a -> Compare [a] cmp xs ys = and (zipWith cmp xs ys) -- we wish to compare a list of lists group :: (Compare a) => [a] -> [[a]] group [] = [] group (x:xs) = let (ys, zs) = span (cmp x) xs in (x:ys) : group zs","title":"Overloading"},{"location":"COMP3161/wk10/tut/#subtyping","text":"","title":"SubTyping"},{"location":"COMP3161/wk10/tut/#coercions-and-subtyping","text":"You are given the type Rectangle , parameterised by its height and width, and the type Square parameterised by the length of one of its sides. Neither type is mutable. a. Which type is the subtype, which type is the supertype? Subtype: Square SuperType: Rectangle b. Give a subtype/supertype ordering of the following set of function types: Rectangle -> Rectangle , Rectangle -> Square , Square -> Rectangle , Square -> Square . graphBT; SqRect --> RectRect; Rect -> Sq ==> Sq -> Rect Any values in p1 -> p2 must exist in t1 -> t2. Fix the return type, a c. Define a data type Square and a data type Rectangle in Haskell. Then define a coercion function from elements of the subclass to elements of the superclass. We first decide whether we change the input of the function, or change the output of the function. d. Show that the ordering you have given in the previous question is correct by defining coercion functions for each pair of types in a subtyping relationship in part (b).","title":"Coercions and Subtyping"},{"location":"COMP3161/wk10/tut/#constructor-variance","text":"List some examples of a covariant , contravariant and invariant type constructor.","title":"Constructor variance"},{"location":"COMP3161/wk10/tut/#lcr-conditions","text":"Consider the following two processes, each manipulating a shared variable x, which starts out at 0. Thread 1 : x:=x+1;x:=x\u22121; Thread 2 : x:=x\u00d72 a) What are the possible final values of x assuming each statement is executed atomically ? 0, 1. b) Rewrite the above program into one where each statement obeys the limited critical reference restriction. What are the possible final values now? -1, 0, 1, 2 c) How could locks be used in your answer to (b) to ensure that only the final results from part (a) are possible? var t; take(l); t := x; x := t + 1; release(l); take(l); t := x; x := t - 1; release(l); var u; take(l); u :=x; x:= u * 2; release(l); After p2, wantp is set to 1 or -1, or abs val is 1. After q2, wantq is set to 1 or -1, or abs bal is 1. in other for both critical sectios to be passed, we must have both await clauses to be true. wantp != wantq, and wantp != -wantq. if both are set to 1 it could run both, we run p2 and q2 at the same time, however we assign only one of them i.e. wantq = -1. then run q3, and pass into the critical section infinitely. then we assign p2. wantp = 1 we check the statement wantp != wantq (1 != -1) which passes into the critical section.","title":"LCR Conditions"},{"location":"COMP3161/wk2/Exercise%201/","text":"Simply putting parentheses is not enough We need different classes such that grouping is non-ambiguous we do this by having a stunt or a class changer","title":"Exercise 1"},{"location":"COMP3161/wk2/Identity%20Laws/","text":"Left Identity : [] ++ ys == ys Right Identity : ys ++[] == ys Associativity: xs ++ (ys ++ zs) == (xs ++ ys) ++ zs","title":"Identity Laws"},{"location":"COMP3161/wk2/Inductive%20Case/","text":"","title":"Inductive Case"},{"location":"COMP3161/wk2/Non%20Simultaneous%20Induction/","text":"RBColour is seperate from RBTree definition Simultaneous - cannot define just one of the conclusion -","title":"Non Simultaneous Induction"},{"location":"COMP3161/wk2/Tut%202%20Revision/","text":"Red Black Tree data RBColour = Red | Black data RBTree = RBLeaf | RBNode RBColour Item RBTree RBTree Red and Black are RBColours. $$ \\frac{}{Red RBColour}\\;\\frac{}{Black RBColour} $$ An RBLeaf is a type of RBTree. $$ \\frac{}{RBLeaf RBTree} $$ A tree can be created from a colour c, an item x, and two RBTrees, t1 and t2. $$ \\frac{c RBColour x Item t_1 RBTree t_2 RBTree}{RBNode c x t_1 t_2 RBTree}A_L $$ In real life, RBTrees are the following cases - Black nodes can have black children - Red nodes cannot have immediate red children Red Root, Black t1, Black t2 We define a subclass OK_R to demonstrate that an OK tree is a tree with a red node. We note the following about our class OK_R t1 OK_R t2 => Black OK OK t1 OK t2 => Red OK_R OK => OK_R (can change OK to OK_R) This satisfies the following - Black trees can be created from two black nodes - Black tress can be createdf rom two red nodes - Black trees... - Red trees can be created only by 2 black nodes (i.e. OK_R cannot be used to construct an OK_R tree)","title":"Tut 2 Revision"},{"location":"COMP3161/wk2/Tut%202/","text":"Inductive Types \u00b6 Consider the (++) operator in Haskell. (++) :: [a] -> [a] -> [a] [] ++ ys = ys (x:xs) ++ ys = x : (xs ++ ys) State the formal properties of left identity , right identity and associativity for (++) . For information look at Identity Laws . Try to prove these properties. In some cases, you may need to perform induction on the structure of lists. The base case of the induction will be for the empty list, and the inductive case will be to show your property for a list (x:xs) , assuming the property for the list xs (this assumption is called the inductive hypothesis ). 1. Left identity x ++ [] = x Right identity [] ++ x = x Associativity (x ++ y) ++ z = x ++ (y ++ z) 2. Left xs ++ [] == xs trivial by definition Right [] ++ xs == xs Base x = [] LHS : [] ++ [] = [] {By 1st definition of (++)} IH : [] ++ ys == ys RTP: [] ++ x:ys == x:ys LHS: [] ++ x:ys = x:ys {By 1st definition of (++)} = RHIS Assoc (x ++ y) ++ z == x ++ (y ++ z) Base: ([] ++ y) ++ z == [] ++ (y ++ z) LHS: ([] ++ y) ++ z = y ++ z {By 1st definition of (++)} RHS: [] ++ (y ++ z) = y ++ z {By 1st definition of (++)} = LHS IH: (xs ++ y) ++ z == xs ++ (y ++ z) RTP: (x:xs ++ y) ++ z == x:xs ++ (y ++ z) LHS: (x:xs ++ y) ++ z = x:(xs ++ y) ++ z {By 2nd definition of (++)} = x:(xs ++ y ++ z) {By 2nd definition of (++)} RHS: x:xs ++ (y ++ z) = x:(xs ++ y ++ z) {By 2nd definition of (++)} = LHS Red Black Trees \u00b6 Red-black trees are binary search trees where each node in the tree is coloured either red or black. In C, red-black trees could, for example, be encoded with the following user-defined data type: typedef struct redBlackNode* link; struct redBlackNode { Item item; // Item type defined elsewhere link left, right; int isRed; // 1 if node is red, 0 if black }; and in Haskell (again, we assume the Item type is defined elsewhere) data RBColour = Red | Black data RBTree = RBLeaf | RBNode RBColour Item RBTree RBTree The user defined Haskell data type characterises a set of terms as RBTree . List the inference rules to define the same set. Assume there already exists a judgement x Item which is derivable for all x- in the Item type. In a proper red-black tree, we can never have a red parent node with a red child, although it is possible to have black nodes with black children. Moreover, the root node cannot be red. Therefore, not all terms of type RBTree are real red-black trees. Define inference rules for a property t OK, such that OK is derivable if the term t represents a proper red-black tree. \\[ \\frac{}{Red\\ RBColour}A_RBC\\;\\frac{}{Black\\ RBColour}A_RBC $$ $$ \\frac{}{RBLeaf\\ RBTree}A_L $$ $$ \\frac{c\\ RBColour\\ \\ x\\ Item\\ \\ t_1\\ RBTree\\ \\ t_2\\ RBTree}{RBNode\\ c\\ \\ x \\ \\ t_1\\ \\ t_2\\ \\ RBTree}A_L \\] 2. $$ \\frac{x Item t_1 OK^R t_2 OK^R}{RBNode Black x t_1 t_2 OK}A_{OK_B} $$ Ambiguity and Syntax \u00b6 Consider the language of boolean expressions (with operators: \u2227 (and), \u2228 (or), \u00ac (not), constant values True and False, and parentheses). Give a simple (non-simultaneous) inductive definition for this language using only judgements of the form e Bool. Identify how this language is ambiguous : That is, find an expression that can be parsed in multiple ways. Now, give a second definition for the same language which is not ambiguous. (to disambiguate: \u00ac has the highest precedence; \u2227 has a higher precedence than \u2228- , both are left associative). Assume you want to prove a property P for all boolean expressions using rule induction over the rules of the first version. Which cases do you have to consider? What is the induction hypothesis for each case? 1. $$ \\frac{}{T Bool}\\;\\frac{}{F Bool}\\; \\frac{e_1 Bool e_2 Bool}{e_1 \u2227 e_2 Bool}\\; \\frac{e_1 Bool e_2 Bool}{e_1 \u2228 e_2 Bool}\\; $$ $$ \\frac{e_1 Bool}{~e_1 Bool}\\; \\frac{e_1 Bool}{(e_1) Bool}\\; $$ This definition is ambiguous, take for example T V T V T. $$ \\dfrac{\\dfrac{\\dfrac{}{T Bool}\\;\\dfrac{}{T Bool} \\;}{{T \u2228 T Bool}\\;}\\dfrac{}{T Bool}}{T \u2228 T \u2228 T Bool} + \\text{mirror image} $$ 3. exp -> Aexp Aexp -> Oexp Aexp & Oexp = e1 ^ e2 Aexp Oexp ^ Aexp = e1 V e2 Oexp Simultaneous Induction \u00b6 In the lecture, we discussed two alternative definitions of a language of parenthesised expressions: In the lecture, we showed that if s M, then s L. Show that the reverse direction of the implication is also true, and therefore M defines the same language as L. Hint : similar to the proof discussed in the lecture, it is not possible to prove it using straight forward rule induction. However, first try induction and to see what is missing, then adjust your proof accordingly. prove a lemma to prove the proof assume sn or sl then sm","title":"Tut 2"},{"location":"COMP3161/wk2/Tut%202/#inductive-types","text":"Consider the (++) operator in Haskell. (++) :: [a] -> [a] -> [a] [] ++ ys = ys (x:xs) ++ ys = x : (xs ++ ys) State the formal properties of left identity , right identity and associativity for (++) . For information look at Identity Laws . Try to prove these properties. In some cases, you may need to perform induction on the structure of lists. The base case of the induction will be for the empty list, and the inductive case will be to show your property for a list (x:xs) , assuming the property for the list xs (this assumption is called the inductive hypothesis ). 1. Left identity x ++ [] = x Right identity [] ++ x = x Associativity (x ++ y) ++ z = x ++ (y ++ z) 2. Left xs ++ [] == xs trivial by definition Right [] ++ xs == xs Base x = [] LHS : [] ++ [] = [] {By 1st definition of (++)} IH : [] ++ ys == ys RTP: [] ++ x:ys == x:ys LHS: [] ++ x:ys = x:ys {By 1st definition of (++)} = RHIS Assoc (x ++ y) ++ z == x ++ (y ++ z) Base: ([] ++ y) ++ z == [] ++ (y ++ z) LHS: ([] ++ y) ++ z = y ++ z {By 1st definition of (++)} RHS: [] ++ (y ++ z) = y ++ z {By 1st definition of (++)} = LHS IH: (xs ++ y) ++ z == xs ++ (y ++ z) RTP: (x:xs ++ y) ++ z == x:xs ++ (y ++ z) LHS: (x:xs ++ y) ++ z = x:(xs ++ y) ++ z {By 2nd definition of (++)} = x:(xs ++ y ++ z) {By 2nd definition of (++)} RHS: x:xs ++ (y ++ z) = x:(xs ++ y ++ z) {By 2nd definition of (++)} = LHS","title":"Inductive Types"},{"location":"COMP3161/wk2/Tut%202/#red-black-trees","text":"Red-black trees are binary search trees where each node in the tree is coloured either red or black. In C, red-black trees could, for example, be encoded with the following user-defined data type: typedef struct redBlackNode* link; struct redBlackNode { Item item; // Item type defined elsewhere link left, right; int isRed; // 1 if node is red, 0 if black }; and in Haskell (again, we assume the Item type is defined elsewhere) data RBColour = Red | Black data RBTree = RBLeaf | RBNode RBColour Item RBTree RBTree The user defined Haskell data type characterises a set of terms as RBTree . List the inference rules to define the same set. Assume there already exists a judgement x Item which is derivable for all x- in the Item type. In a proper red-black tree, we can never have a red parent node with a red child, although it is possible to have black nodes with black children. Moreover, the root node cannot be red. Therefore, not all terms of type RBTree are real red-black trees. Define inference rules for a property t OK, such that OK is derivable if the term t represents a proper red-black tree. \\[ \\frac{}{Red\\ RBColour}A_RBC\\;\\frac{}{Black\\ RBColour}A_RBC $$ $$ \\frac{}{RBLeaf\\ RBTree}A_L $$ $$ \\frac{c\\ RBColour\\ \\ x\\ Item\\ \\ t_1\\ RBTree\\ \\ t_2\\ RBTree}{RBNode\\ c\\ \\ x \\ \\ t_1\\ \\ t_2\\ \\ RBTree}A_L \\] 2. $$ \\frac{x Item t_1 OK^R t_2 OK^R}{RBNode Black x t_1 t_2 OK}A_{OK_B} $$","title":"Red Black Trees"},{"location":"COMP3161/wk2/Tut%202/#ambiguity-and-syntax","text":"Consider the language of boolean expressions (with operators: \u2227 (and), \u2228 (or), \u00ac (not), constant values True and False, and parentheses). Give a simple (non-simultaneous) inductive definition for this language using only judgements of the form e Bool. Identify how this language is ambiguous : That is, find an expression that can be parsed in multiple ways. Now, give a second definition for the same language which is not ambiguous. (to disambiguate: \u00ac has the highest precedence; \u2227 has a higher precedence than \u2228- , both are left associative). Assume you want to prove a property P for all boolean expressions using rule induction over the rules of the first version. Which cases do you have to consider? What is the induction hypothesis for each case? 1. $$ \\frac{}{T Bool}\\;\\frac{}{F Bool}\\; \\frac{e_1 Bool e_2 Bool}{e_1 \u2227 e_2 Bool}\\; \\frac{e_1 Bool e_2 Bool}{e_1 \u2228 e_2 Bool}\\; $$ $$ \\frac{e_1 Bool}{~e_1 Bool}\\; \\frac{e_1 Bool}{(e_1) Bool}\\; $$ This definition is ambiguous, take for example T V T V T. $$ \\dfrac{\\dfrac{\\dfrac{}{T Bool}\\;\\dfrac{}{T Bool} \\;}{{T \u2228 T Bool}\\;}\\dfrac{}{T Bool}}{T \u2228 T \u2228 T Bool} + \\text{mirror image} $$ 3. exp -> Aexp Aexp -> Oexp Aexp & Oexp = e1 ^ e2 Aexp Oexp ^ Aexp = e1 V e2 Oexp","title":"Ambiguity and Syntax"},{"location":"COMP3161/wk2/Tut%202/#simultaneous-induction","text":"In the lecture, we discussed two alternative definitions of a language of parenthesised expressions: In the lecture, we showed that if s M, then s L. Show that the reverse direction of the implication is also true, and therefore M defines the same language as L. Hint : similar to the proof discussed in the lecture, it is not possible to prove it using straight forward rule induction. However, first try induction and to see what is missing, then adjust your proof accordingly. prove a lemma to prove the proof assume sn or sl then sm","title":"Simultaneous Induction"},{"location":"COMP3161/wk3/Lec%202/","text":"Semantics are made up from dynamic and static elements. Dynamic Semantics - what programs actually do Dynamic \u00b6 Behaviour - Final Result Cost - Resources - Time - Space Static semantics aspects of P that can be determined without running the program e.g. Arith ::= Num Nat | Var String | Plus Arith Arith | Times Arith Arith | Let String Arith Arith We can check from static semantic if the program is well-scoped. Gamma is context. ok is a binary judgement on context and terms. Unprovable because its an empty set and we want to find x bound. We started from empty context. y bound == example y is a global variable and cannt be used or \"bound\". .","title":"Lec 2"},{"location":"COMP3161/wk3/Lec%202/#dynamic","text":"Behaviour - Final Result Cost - Resources - Time - Space Static semantics aspects of P that can be determined without running the program e.g. Arith ::= Num Nat | Var String | Plus Arith Arith | Times Arith Arith | Let String Arith Arith We can check from static semantic if the program is well-scoped. Gamma is context. ok is a binary judgement on context and terms. Unprovable because its an empty set and we want to find x bound. We started from empty context. y bound == example y is a global variable and cannt be used or \"bound\". .","title":"Dynamic"},{"location":"COMP3161/wk3/Tut%203/","text":"Parsing Relation \u00b6 Using the inference rules for the parsing relation of arithmetic expressions given in the syntax slides , derive the abstract syntax corresponding to the concrete syntax 3 + let x = 5 in x + 2 end . (Num 3) Plus (x ) Substitution \u00b6 What is the result of the substitution in the following expressions? (Let x (y. (Plus (Num 1) x)))[x:=y] (Plus (Num 1) x) = x + 1 (Let y (z. (Plus (Num 1) z))[x:=y] (Let x (z. (Plus x z))[x:=y] (Let x (x. (Plus (Num 1) x))[x:=y] Semantics \u00b6 You may want to look at the W3 Thursday notes before attempting these questions. A robot moves along a grid according to a simple program. The program consists of a sequence of commands move and turn , separated by semicolons, with the command sequence terminated by the keyword stop : R::=move; R | turn; R | stop Initially, the robot faces east and starts at the grid coordinates (0,0) . The command turn causes the robot to turn 90 degrees counter-clockwise, and move to move one unit in the direction it is facing. Denotational Semantics \u00b6 First, devise a suitable denotational semantics for this language. For this exercise, we are only interested in the final position of the robot, so the mathematical object which we associate to the sequence of instructions should merely be the final coordinates of the robot as a 2D vector. [[\u22c5]]:R\u2192Z2 Operational Semantics \u00b6 Small-Step Semantics \u00b6 Next, we will devise a set of small-step semantics rules for this language. This means determining answers to the following questions: What is the set of states? Which of those states are final states, and which are initial states? What transitions exist between those states? Big-Step Semantics \u00b6 Lastly, we will devise a set of big-step evaluation rules for this language. This means determining answers to the following questions: What is the set of evaluable expressions? What is the set of values? How do evaluable expressions evaluate to those values? Lambda calculus and binding \u00b6 Reduction \u00b6 Apply \u03b2 and \u03b7 reduction as much as possible to this term, until you reach a normal form . Where necessary, use \u03b1 renaming to avoid capture. (\u03bbn f x. f (n x x)) (\u03bbf x. f) de Bruijn Indices \u00b6 How would the above \u03bb term be represented in de Bruijn indices? Repeat the same reduction with de Bruijn indices.","title":"Tut 3"},{"location":"COMP3161/wk3/Tut%203/#parsing-relation","text":"Using the inference rules for the parsing relation of arithmetic expressions given in the syntax slides , derive the abstract syntax corresponding to the concrete syntax 3 + let x = 5 in x + 2 end . (Num 3) Plus (x )","title":"Parsing Relation"},{"location":"COMP3161/wk3/Tut%203/#substitution","text":"What is the result of the substitution in the following expressions? (Let x (y. (Plus (Num 1) x)))[x:=y] (Plus (Num 1) x) = x + 1 (Let y (z. (Plus (Num 1) z))[x:=y] (Let x (z. (Plus x z))[x:=y] (Let x (x. (Plus (Num 1) x))[x:=y]","title":"Substitution"},{"location":"COMP3161/wk3/Tut%203/#semantics","text":"You may want to look at the W3 Thursday notes before attempting these questions. A robot moves along a grid according to a simple program. The program consists of a sequence of commands move and turn , separated by semicolons, with the command sequence terminated by the keyword stop : R::=move; R | turn; R | stop Initially, the robot faces east and starts at the grid coordinates (0,0) . The command turn causes the robot to turn 90 degrees counter-clockwise, and move to move one unit in the direction it is facing.","title":"Semantics"},{"location":"COMP3161/wk3/Tut%203/#denotational-semantics","text":"First, devise a suitable denotational semantics for this language. For this exercise, we are only interested in the final position of the robot, so the mathematical object which we associate to the sequence of instructions should merely be the final coordinates of the robot as a 2D vector. [[\u22c5]]:R\u2192Z2","title":"Denotational Semantics"},{"location":"COMP3161/wk3/Tut%203/#operational-semantics","text":"","title":"Operational Semantics"},{"location":"COMP3161/wk3/Tut%203/#small-step-semantics","text":"Next, we will devise a set of small-step semantics rules for this language. This means determining answers to the following questions: What is the set of states? Which of those states are final states, and which are initial states? What transitions exist between those states?","title":"Small-Step Semantics"},{"location":"COMP3161/wk3/Tut%203/#big-step-semantics","text":"Lastly, we will devise a set of big-step evaluation rules for this language. This means determining answers to the following questions: What is the set of evaluable expressions? What is the set of values? How do evaluable expressions evaluate to those values?","title":"Big-Step Semantics"},{"location":"COMP3161/wk3/Tut%203/#lambda-calculus-and-binding","text":"","title":"Lambda calculus and binding"},{"location":"COMP3161/wk3/Tut%203/#reduction","text":"Apply \u03b2 and \u03b7 reduction as much as possible to this term, until you reach a normal form . Where necessary, use \u03b1 renaming to avoid capture. (\u03bbn f x. f (n x x)) (\u03bbf x. f)","title":"Reduction"},{"location":"COMP3161/wk3/Tut%203/#de-bruijn-indices","text":"How would the above \u03bb term be represented in de Bruijn indices? Repeat the same reduction with de Bruijn indices.","title":"de Bruijn Indices"},{"location":"COMP3161/wk4/Tut%204/","text":"FV(e) \\(\\subseteq\\) Empty cannot happen. transitivty sigma 1 -> sigma 2 -> sigma 3 sigma 1 -> sigma 3 $$ \\dfrac{\\sigma_1, (s_1;s_2)\\Downarrow \\sigma' s_3}{(\\sigma_1, (s_1;s_2); s_3)} $$ We just state for \\(\\exists\\ \\sigma', \\sigma''\\) that \\((\\sigma_1, s_1) \\Downarrow \\sigma''\\) do s until e \\(\\equiv\\) s; while \\(\\neg e\\) do s od \\[\\dfrac{\\dfrac{}{\\{\\varphi\\}\\ s\\ \\{\\varphi\\}}\\quad\\{\\varphi\\}\\ while\\ \\neg e\\ do\\ s \\ od\\ \\{\\varphi\\ \\wedge\\ e\\}}{\\{\\varphi\\}\\ s;while\\ \\neg e\\ do\\ s \\ od\\ \\{\\varphi\\ \\wedge\\ e\\}}\\] \\[ \\{\\varphi\\}\\ while\\ \\neg e\\ do\\ s \\ od\\ \\{\\varphi\\ \\wedge\\ e\\} \\]","title":"Tut 4"},{"location":"COMP3161/wk5/Cost%20Models/","text":"A cost model is a mathematical model that measures the cost of executing a program. -- how to evaluate the cost of a machine Operation Cost Model \u00b6 Time cost is determined by counting the number of steps it takes to finish. Abstract Machine (M Machine) \u00b6 An abstract machine consists of: A set of states \\(\\sum\\) A set of initial states \\(I \\subseteq \\sum\\) A set of final states \\(F \\subseteq \\sum\\) A transition relation \\(\\mapsto \\subseteq \\sum \\times \\sum\\) (small step definition) small explanation e1 evals to e1' so machine wise, they are the same v is a function left side is also a function apply recfun f.x.e. v for all x, replace with v bu -- however there are issues with applying this idea to small step We expect a machine to perform small step in O(1) time. However this is not the case for evaling. Two problems: - Substitution occurs in function application, which is potentially O(n) time (we dont know what 1 step leads to) - Control Flow is not explicit - (do we know that the recursive step oneStep e_1 evals to Num n?) eval (Num n) = n eval e = eval (oneStep e) [We dont know if substitution is O(1)] oneStep (Plus (Num n) (Num m)) = Num (n + m) oneStep (Plus (Num n) e_2) = Plus (Num n) (oneStep e_2) oneStep (Plus e_1 e_2) = Plus (oneStep e_1) e_2 -- substitution is potentially O(n) The C Machine \u00b6 We define a machine where all the rules are axioms, without recursive definitions. This is typically implemented into a stack, where at every small step, we consider the stack and expression. Frames |> Stack Unsolvable expressions are normally called frames. ---- (Plus 3 \"\") where \"\" is being evaluated - Explicit information that is evaluated are put on the 'stack' --- (Frames) |> eval Num 3 Evaluating in C machine \u00b6 Now if we evaluate, we use the rules below. Example: Plus (Plus 2 3) 4) \u00b6 Take for example Plus e_1 e_2 In English we want to evaluate in the order: Plus e_1 e_2 -> Plus (eval e_1) e_2 -> Plus v1 e_2 -> Plus v1 (eval e_2) -> Plus v1 v2 -> v1 + v2 In the stack we want to store (current) unsolvable exprs as frames. Other Rules \u00b6 Here are the rest of the rules Definition of C Machine \u00b6 Control Flow Machine All rules are axioms - the evaluator can run until the stack is solved We have a lower-level specification Substitution is still a machine operation - still not O(1) per step since substitution is not O(1) Comparison C vs M machines \u00b6 C machines are more detailed than M machines, but they both produce the same result. This is called explicit stacks How to Prove Refinement \u00b6 We have assumed that the C machine works the same as the M machine, but how do we prove it? Abstraction Function \u00b6 This is essentially pattern matching from C machine to M machine. We define three simple rules, which can be applied inductively Case 1 : Plus e_1 e_2 \u00b6 Case 2 : Plus _ e2 \u00b6 Case 3 : Plus e1 _ \u00b6","title":"Cost Models"},{"location":"COMP3161/wk5/Cost%20Models/#operation-cost-model","text":"Time cost is determined by counting the number of steps it takes to finish.","title":"Operation Cost Model"},{"location":"COMP3161/wk5/Cost%20Models/#abstract-machine-m-machine","text":"An abstract machine consists of: A set of states \\(\\sum\\) A set of initial states \\(I \\subseteq \\sum\\) A set of final states \\(F \\subseteq \\sum\\) A transition relation \\(\\mapsto \\subseteq \\sum \\times \\sum\\) (small step definition) small explanation e1 evals to e1' so machine wise, they are the same v is a function left side is also a function apply recfun f.x.e. v for all x, replace with v bu -- however there are issues with applying this idea to small step We expect a machine to perform small step in O(1) time. However this is not the case for evaling. Two problems: - Substitution occurs in function application, which is potentially O(n) time (we dont know what 1 step leads to) - Control Flow is not explicit - (do we know that the recursive step oneStep e_1 evals to Num n?) eval (Num n) = n eval e = eval (oneStep e) [We dont know if substitution is O(1)] oneStep (Plus (Num n) (Num m)) = Num (n + m) oneStep (Plus (Num n) e_2) = Plus (Num n) (oneStep e_2) oneStep (Plus e_1 e_2) = Plus (oneStep e_1) e_2 -- substitution is potentially O(n)","title":"Abstract Machine (M Machine)"},{"location":"COMP3161/wk5/Cost%20Models/#the-c-machine","text":"We define a machine where all the rules are axioms, without recursive definitions. This is typically implemented into a stack, where at every small step, we consider the stack and expression. Frames |> Stack Unsolvable expressions are normally called frames. ---- (Plus 3 \"\") where \"\" is being evaluated - Explicit information that is evaluated are put on the 'stack' --- (Frames) |> eval Num 3","title":"The C Machine"},{"location":"COMP3161/wk5/Cost%20Models/#evaluating-in-c-machine","text":"Now if we evaluate, we use the rules below.","title":"Evaluating in C machine"},{"location":"COMP3161/wk5/Cost%20Models/#example-plus-plus-2-3-4","text":"Take for example Plus e_1 e_2 In English we want to evaluate in the order: Plus e_1 e_2 -> Plus (eval e_1) e_2 -> Plus v1 e_2 -> Plus v1 (eval e_2) -> Plus v1 v2 -> v1 + v2 In the stack we want to store (current) unsolvable exprs as frames.","title":"Example: Plus (Plus 2 3) 4)"},{"location":"COMP3161/wk5/Cost%20Models/#other-rules","text":"Here are the rest of the rules","title":"Other Rules"},{"location":"COMP3161/wk5/Cost%20Models/#definition-of-c-machine","text":"Control Flow Machine All rules are axioms - the evaluator can run until the stack is solved We have a lower-level specification Substitution is still a machine operation - still not O(1) per step since substitution is not O(1)","title":"Definition of C Machine"},{"location":"COMP3161/wk5/Cost%20Models/#comparison-c-vs-m-machines","text":"C machines are more detailed than M machines, but they both produce the same result. This is called explicit stacks","title":"Comparison C vs M machines"},{"location":"COMP3161/wk5/Cost%20Models/#how-to-prove-refinement","text":"We have assumed that the C machine works the same as the M machine, but how do we prove it?","title":"How to Prove Refinement"},{"location":"COMP3161/wk5/Cost%20Models/#abstraction-function","text":"This is essentially pattern matching from C machine to M machine. We define three simple rules, which can be applied inductively","title":"Abstraction Function"},{"location":"COMP3161/wk5/Cost%20Models/#case-1-plus-e_1-e_2","text":"","title":"Case 1 : Plus e_1 e_2"},{"location":"COMP3161/wk5/Cost%20Models/#case-2-plus-_-e2","text":"","title":"Case 2 : Plus _ e2"},{"location":"COMP3161/wk5/Cost%20Models/#case-3-plus-e1-_","text":"","title":"Case 3 : Plus e1 _"},{"location":"COMP3161/wk5/TinyImp/","text":"TinyImp Definition \u00b6 We define TinyImp as a language based on structural programming. The syntax consists of statements and expressions. Stmt ::= skip Do nothing | x := Expr Assignment | var y \u00b7 Stmt Declaration | if Expr then Stmt else Stmt fi Conditional | while Expr do Stmt od Loop | Stmt ; Stmt Sequencing Expr ::= \u3008Arithmetic expressions\u3009 Some example functions can be written in this format. // Factorial var i \u00b7 var m \u00b7 i := 0; m := 1; while i < N do i := i + 1; m := m \u00d7 i od // Fibonacci var m \u00b7 var n \u00b7 var i \u00b7 m := 1; n := 1; i := 1; while i < N do var t \u00b7 t := m; m := n; n := m + t; i := i + 1 od Checking Syntax in TinyImp \u00b6 Variables need to be checked in this syntax, since we can write valid syntax, but fails to run. var m m := n + 1; // n is not declared Simple Definitions#Free Variable Simple Definitions#Initialized Variable In essence: - U is the declared variables - V is the initialized variables (have a current value) - W is which variables are newly initialized from running (definitely written to) So now we create some checking rules for variables using U V and W. Skip \u00b6 In the skip program, skip is ok, then no unsafe writes happens. W is the definitely written variables (where nothing was written to) Assignment \u00b6 x := Expr We assume the statement x:=e is ok, giving us W. We need to check that x is free and not initialized, or we overwrite a value. We need to check that inside the expression e, we are not using undeclared variable (runtime error), so we check all free variables in e are declared. This gives us x inside of W, since we changed x. Variables \u00b6 If y is free, then we can initialize var y. But what if the statement s uses the variable. if s initializes y, then we dont keep the value in the outer function. If then else \u00b6 We need the guard to have declared variables. FV(e) statement 1 definitely defines W_1. statement 2 definitely defines W_2. W is the definitely declared variables of both statements. Hence its the variables that exist in W_1 and W_2. Or the intersection of both sets. While \u00b6 The definitely declared variables is zero. This is because the loop can run zero times. We need to know that the variables we are using are written to already. We just define, but dont use the definitely declared variables in the do statement. When we run s1, we know the variables definitively set are W_1. Then we run statement 2, using the context of the previous statement. Hence s1 produces W_1, and s2 must use them as declared variables. And the final result depends on both statements definitely defined variables. Dynamic Semantics \u00b6 We will use big-step operational semantics. What are the sets of evaluable expressions and values here? Evaluable Expressions: A pair containing a statement to execute and a state \u03c3. Values: The final state that results from executing the statement. States: mutable mappings from states to values. For every loop interaction we apply the bottom right rule n times. Uninitialized Variables \u00b6 We can evaluate this behaviour in the big step semantics, and prove its impossible. But what if we wanted to define actual behaviour for this (make it valid compile and run) Crash and Burn \u00b6 Using an uninitialized variable is undefined, and does not 'reduce' to a value. Default Value \u00b6 Using Java, declarations of variables have a default value of 0. So whenever we declare a variable, we set it to 0. Junk Data \u00b6 Using C, we can allocate memory but we havent cleared the value yet. - When declaring x, We get a random value n (default value is not zero)","title":"TinyImp"},{"location":"COMP3161/wk5/TinyImp/#tinyimp-definition","text":"We define TinyImp as a language based on structural programming. The syntax consists of statements and expressions. Stmt ::= skip Do nothing | x := Expr Assignment | var y \u00b7 Stmt Declaration | if Expr then Stmt else Stmt fi Conditional | while Expr do Stmt od Loop | Stmt ; Stmt Sequencing Expr ::= \u3008Arithmetic expressions\u3009 Some example functions can be written in this format. // Factorial var i \u00b7 var m \u00b7 i := 0; m := 1; while i < N do i := i + 1; m := m \u00d7 i od // Fibonacci var m \u00b7 var n \u00b7 var i \u00b7 m := 1; n := 1; i := 1; while i < N do var t \u00b7 t := m; m := n; n := m + t; i := i + 1 od","title":"TinyImp Definition"},{"location":"COMP3161/wk5/TinyImp/#checking-syntax-in-tinyimp","text":"Variables need to be checked in this syntax, since we can write valid syntax, but fails to run. var m m := n + 1; // n is not declared Simple Definitions#Free Variable Simple Definitions#Initialized Variable In essence: - U is the declared variables - V is the initialized variables (have a current value) - W is which variables are newly initialized from running (definitely written to) So now we create some checking rules for variables using U V and W.","title":"Checking Syntax in TinyImp"},{"location":"COMP3161/wk5/TinyImp/#skip","text":"In the skip program, skip is ok, then no unsafe writes happens. W is the definitely written variables (where nothing was written to)","title":"Skip"},{"location":"COMP3161/wk5/TinyImp/#assignment","text":"x := Expr We assume the statement x:=e is ok, giving us W. We need to check that x is free and not initialized, or we overwrite a value. We need to check that inside the expression e, we are not using undeclared variable (runtime error), so we check all free variables in e are declared. This gives us x inside of W, since we changed x.","title":"Assignment"},{"location":"COMP3161/wk5/TinyImp/#variables","text":"If y is free, then we can initialize var y. But what if the statement s uses the variable. if s initializes y, then we dont keep the value in the outer function.","title":"Variables"},{"location":"COMP3161/wk5/TinyImp/#if-then-else","text":"We need the guard to have declared variables. FV(e) statement 1 definitely defines W_1. statement 2 definitely defines W_2. W is the definitely declared variables of both statements. Hence its the variables that exist in W_1 and W_2. Or the intersection of both sets.","title":"If then else"},{"location":"COMP3161/wk5/TinyImp/#while","text":"The definitely declared variables is zero. This is because the loop can run zero times. We need to know that the variables we are using are written to already. We just define, but dont use the definitely declared variables in the do statement. When we run s1, we know the variables definitively set are W_1. Then we run statement 2, using the context of the previous statement. Hence s1 produces W_1, and s2 must use them as declared variables. And the final result depends on both statements definitely defined variables.","title":"While"},{"location":"COMP3161/wk5/TinyImp/#dynamic-semantics","text":"We will use big-step operational semantics. What are the sets of evaluable expressions and values here? Evaluable Expressions: A pair containing a statement to execute and a state \u03c3. Values: The final state that results from executing the statement. States: mutable mappings from states to values. For every loop interaction we apply the bottom right rule n times.","title":"Dynamic Semantics"},{"location":"COMP3161/wk5/TinyImp/#uninitialized-variables","text":"We can evaluate this behaviour in the big step semantics, and prove its impossible. But what if we wanted to define actual behaviour for this (make it valid compile and run)","title":"Uninitialized Variables"},{"location":"COMP3161/wk5/TinyImp/#crash-and-burn","text":"Using an uninitialized variable is undefined, and does not 'reduce' to a value.","title":"Crash and Burn"},{"location":"COMP3161/wk5/TinyImp/#default-value","text":"Using Java, declarations of variables have a default value of 0. So whenever we declare a variable, we set it to 0.","title":"Default Value"},{"location":"COMP3161/wk5/TinyImp/#junk-data","text":"Using C, we can allocate memory but we havent cleared the value yet. - When declaring x, We get a random value n (default value is not zero)","title":"Junk Data"},{"location":"COMP3161/wk5/tut5/","text":"Most imperative programming languages do not make the else clause of an if statement mandatory. TinyImp only has the if then else form. How can a stand-alone if be encoded in TinyImp? Conversely, how can if then else be encoded using only stand-alone if- in TinyImp? MinHS doesn't have stand-alone if, a design decision shared by most functional programming languages. Unlike TinyImp, there's no sensible way of encoding it. Why is it difficult to encode, and why do you think the language has been designed this way? TinyImp#TinyImp Definition 1.1. if b then e fi === if b then e else skip fi 1.2. (we want to create if then else with an unknown guard) In the following, we assume x is a fresh variable, i.e.,one that doesn't occur free anywhere in e1, e2 or b. To see why we bother with x, consider what happens if the truth value of b changes as a result of executing e1. if b then e fi === varx\u22c5 x:=b; if x then e1 fi; if \u00acx then e2 fi 1.3. The if in TinyImp is a statement and therefore has no value, only side-effects. Hence there's a clear choice of what to do when the guard is false: nothing. In MinHS, if then else is an expression, and wea would like expressions to have values. In the absence of an else branch, it's not clear what value we should assign to an expression whose guard is false. If we really want to go ahead with this, we might consider the following choices. First, we could say that if expressions whose guard are false have no value, and cause the program to diverge or abort. Second, we could associate a \"default\" value to every type, and use this value as a fallback. There's nothing inherently wrong with either choice, but both seem to run against the programmer's intution that nothing should happen. Abstract Machines \u00b6 We label the stack as P Rule 1 If we are evaling P on the stack, then we return P. if s \\(\\prec\\) P \\(\\mapsto\\) s \\(\\succ\\) P if we are evaling a+b, we want to eval the left side first so we place a box in the place of the a. If we are have p + box as a frame, and have a value A on the stack, we can remove the frame and return P + A == AP.","title":"Tut5"},{"location":"COMP3161/wk5/tut5/#abstract-machines","text":"We label the stack as P Rule 1 If we are evaling P on the stack, then we return P. if s \\(\\prec\\) P \\(\\mapsto\\) s \\(\\succ\\) P if we are evaling a+b, we want to eval the left side first so we place a box in the place of the a. If we are have p + box as a frame, and have a value A on the stack, we can remove the frame and return P + A == AP.","title":"Abstract Machines"},{"location":"COMP3161/wk7/Safety%20and%20Liveness/","text":"","title":"Safety and Liveness"},{"location":"COMP3161/wk7/tut%207/","text":"The E-Machine A further","title":"Tut 7"},{"location":"COMP3161/wk8/Damas-Milner%20Type%20Inference/","text":"Implicit Typed MinHS \u00b6 We have the definition recfun f x = fst + 1 Int x h","title":"Damas Milner Type Inference"},{"location":"COMP3161/wk8/Damas-Milner%20Type%20Inference/#implicit-typed-minhs","text":"We have the definition recfun f x = fst + 1 Int x h","title":"Implicit Typed MinHS"},{"location":"COMP3161/wk8/Simple%20Definitions/","text":"Atomic Elements \u00b6 We run the entire program without any interjections/stopping Thread 1 : x:= x + 1; x:= x - 1; Thread 2 : x:= x ** 2; Limited Critical Reference \u00b6 Any line of code access a variables two times, we don't know which occurs first. Functional Programming Language \u00b6 In essence, a programming language which allows lambda. Examples: Haskell, JavaScript, (Lisp?) Quaternary Judgement \u00b6 _ ; _ \u22a2 _ ok \u21dd _ Free Variable \u00b6 A variable that is declared, that can be written to. Initialized Variable \u00b6 A variable that has been declared, and has a value. var y \u2b1d // here, y is declared (free) var x \u2b1d // here, y,x are declared (free) y := 0; // here, y is declared and initialised, x is declared x := y + 1 // here, x,y are declared and initialised","title":"Simple Definitions"},{"location":"COMP3161/wk8/Simple%20Definitions/#atomic-elements","text":"We run the entire program without any interjections/stopping Thread 1 : x:= x + 1; x:= x - 1; Thread 2 : x:= x ** 2;","title":"Atomic Elements"},{"location":"COMP3161/wk8/Simple%20Definitions/#limited-critical-reference","text":"Any line of code access a variables two times, we don't know which occurs first.","title":"Limited Critical Reference"},{"location":"COMP3161/wk8/Simple%20Definitions/#functional-programming-language","text":"In essence, a programming language which allows lambda. Examples: Haskell, JavaScript, (Lisp?)","title":"Functional Programming Language"},{"location":"COMP3161/wk8/Simple%20Definitions/#quaternary-judgement","text":"_ ; _ \u22a2 _ ok \u21dd _","title":"Quaternary Judgement"},{"location":"COMP3161/wk8/Simple%20Definitions/#free-variable","text":"A variable that is declared, that can be written to.","title":"Free Variable"},{"location":"COMP3161/wk8/Simple%20Definitions/#initialized-variable","text":"A variable that has been declared, and has a value. var y \u2b1d // here, y is declared (free) var x \u2b1d // here, y,x are declared (free) y := 0; // here, y is declared and initialised, x is declared x := y + 1 // here, x,y are declared and initialised","title":"Initialized Variable"},{"location":"COMP3161/wk9/Monad%20Tutorial/","text":"Abstract Nonsense \u00b6 A monad is a type constructor m, with two functions: return \"return\" has the form a -> m a >>= \"bind\" m a -> (a -> m b) -> m b where a and b are type variables (universally quantified) return is the left and right identity laws // if i have m and that is passed into return, i get m // if i have a value and pass that into a function, i get f (x) m >>= return = m return x >>= m = m x bind abstracts computation via the >>= command Take for a calculator we want the following behaviour plus e1 e2 eval left return if error eval right return if error. return left + right Plus :: Plus e1 e2 = case eval e1 of Nothing -> Nothing Just x -> ( case eval e2 Nothing -> Nothing Just y -> x + y ) We improve this code using two standard librarys in haskell. 1. Maybe monad This has return and bind. but it also stops running and returns nothing if error. 2. do notation do is syntactic sugar for run this line, if it fails then return the failure ```haskell calc'' (Num n) = return n calc'' (Plus e1 e2) = do n <- eval e1 -- stops running at this point m <- eval e2 -- need the context of e1 essentially return $ n + m ``` TC Monad - Makes error handling simplier - Generates fresh names we dont have to worry about","title":"Monad Tutorial"},{"location":"COMP3161/wk9/Monad%20Tutorial/#abstract-nonsense","text":"A monad is a type constructor m, with two functions: return \"return\" has the form a -> m a >>= \"bind\" m a -> (a -> m b) -> m b where a and b are type variables (universally quantified) return is the left and right identity laws // if i have m and that is passed into return, i get m // if i have a value and pass that into a function, i get f (x) m >>= return = m return x >>= m = m x bind abstracts computation via the >>= command Take for a calculator we want the following behaviour plus e1 e2 eval left return if error eval right return if error. return left + right Plus :: Plus e1 e2 = case eval e1 of Nothing -> Nothing Just x -> ( case eval e2 Nothing -> Nothing Just y -> x + y ) We improve this code using two standard librarys in haskell. 1. Maybe monad This has return and bind. but it also stops running and returns nothing if error. 2. do notation do is syntactic sugar for run this line, if it fails then return the failure ```haskell calc'' (Num n) = return n calc'' (Plus e1 e2) = do n <- eval e1 -- stops running at this point m <- eval e2 -- need the context of e1 essentially return $ n + m ``` TC Monad - Makes error handling simplier - Generates fresh names we dont have to worry about","title":"Abstract Nonsense"},{"location":"COMP3161/wk9/SubTyping/","text":"To add subtyping to a language, we define a partial order on types \\(\\tau \\leq p\\) and a rule of subsumption: $$ \\dfrac{}{} $$ Subtyping allows java programs to declare subclasses. class Pig extends Animal{} // Anywhere that an Animal is input, we can supply Pig If you have an expression of type tau and tau is a subtype of p. then we can treat the expression as type p. $$ \\dfrac{\\Gamma \\vdash e : \\tau \\quad \\tau \\leq q}{\\Gamma \\vdash upcast \\rho e : \\rho} $$ Partial ordering is reflexive transitive and associative Reflexive : forall a, a is a subtype of itself Transitive forall a b c, if a is a subset of b and b is a subset of c, and a is a subset of c. i.e. BlackSheep <= Sheep <= Animal, Animal bs = new BlackSheep(); Antisymmetric: \"no cycles\" forall a b if a <= b and b <= a, then a == b. Partial Ordering definition \u00b6 There are two main approaches for what subtypes do. Upcasting \u00b6 upcast \\(v \\mapsto v\\) This requires type \\(\\tau\\) could be judged to have type \\(p\\) . For example Int <= Float 3 + 2.2 Coercion \u00b6 We set tau to be type p in runtime. we try 3 + 2.2 3 gets typed to float at runtime Subtyping should be Coherent \u00b6 We could get different results if we use coercion. 3 + \"hello\" --> \"3hello\" (Int <= String) 3 + \"hello\" --> 3.0 + \"hello\" --> \"3.0hello\" (Int <= Float) --> (Float <= String) This is an issue with bad coercion. So we would normally enforce that subtype coercions are coherent , meaning that the result must be the same regardless of which coercion was used first. Behavioural Subtyping \u00b6 Another constraint on subtypes is that syntactic subtypes should correspond to semantic. Liskov Substitution Principle \u00b6 Let f(x) be a property provable about objects x of type p. Then f(y) should be true for objects of type t where t is a subtype of p. Violation If Rectangle <= Square Then Area(Square) = s^2. But this doesnt work for Rectangles. Product Types \u00b6 Assuming Int \\(\\leq\\) Float Suppose I have a coercion function c: Int \\(\\mapsto\\) Float Can I use that to write coercion functions for handling 2 different product types. We draw the following coercion diagram: graph BT; IntXInt --> IntXFloat; IntXInt --> FloatXInt; FloatXInt --> FloatXFloat; IntXFloat --> FloatXFloat; And yes. We can create the coercion functions: c:: Int -> Float c n = Float n c1 :: (Int -> Int) -> (Int -> Float) (IntXFloat) c1 (n, m) = (n, c m) c2 :: (Int -> Int) -> (Float -> Int) (IntXFloat) c2 (n, m) = (c n, m) NOTE how we have 2 functions for 1 output c3 :: (Float -> Int) -> (Float -> Float) (FloatXFloat) c3 (n, m) = (n, c m) c4 :: (Int -> Float) -> (Float -> Float) (FloatXFloat) c4 (n, m) = (c n, m) So we can conclude for product types In order for a product type to be a subtype of another subtype, the rows before must be a subtype of the rows after. \\[ \\dfrac{\\tau_1 \\leq p_1 \\quad \\tau_2 \\leq p_2}{(\\tau_1\\times\\tau_2)\\leq(p_1 \\times p_2)} \\] Sum Types \u00b6 Same as product types. Function Types \u00b6 Suppose we wanted to change a function from Int -> Int to Int -> Float. We assume c is Int -> Float. Say the function is named itoi, (int to int), and we want a coercion function named c1. itoi = take in an int and returns an int. so we want the result of itoi. or in other words for an \"int x\", \\x -> itoi x c1 itoi = take in an int, and make it a float we have c. c1 itoi = \\x -> c (itoi x) We cannot use coercion here normally. After applying the following relationships. graph BT; IntToInt --> IntToFloat; FloatToInt --> IntToInt; FloatToInt --> FloatToFloat; IntToFloat --> FloatToFloat; If I want a function from Float to Int Invariants, Co-variants and Contravariants \u00b6","title":"SubTyping"},{"location":"COMP3161/wk9/SubTyping/#partial-ordering-definition","text":"There are two main approaches for what subtypes do.","title":"Partial Ordering definition"},{"location":"COMP3161/wk9/SubTyping/#upcasting","text":"upcast \\(v \\mapsto v\\) This requires type \\(\\tau\\) could be judged to have type \\(p\\) . For example Int <= Float 3 + 2.2","title":"Upcasting"},{"location":"COMP3161/wk9/SubTyping/#coercion","text":"We set tau to be type p in runtime. we try 3 + 2.2 3 gets typed to float at runtime","title":"Coercion"},{"location":"COMP3161/wk9/SubTyping/#subtyping-should-be-coherent","text":"We could get different results if we use coercion. 3 + \"hello\" --> \"3hello\" (Int <= String) 3 + \"hello\" --> 3.0 + \"hello\" --> \"3.0hello\" (Int <= Float) --> (Float <= String) This is an issue with bad coercion. So we would normally enforce that subtype coercions are coherent , meaning that the result must be the same regardless of which coercion was used first.","title":"Subtyping should be Coherent"},{"location":"COMP3161/wk9/SubTyping/#behavioural-subtyping","text":"Another constraint on subtypes is that syntactic subtypes should correspond to semantic.","title":"Behavioural Subtyping"},{"location":"COMP3161/wk9/SubTyping/#liskov-substitution-principle","text":"Let f(x) be a property provable about objects x of type p. Then f(y) should be true for objects of type t where t is a subtype of p. Violation If Rectangle <= Square Then Area(Square) = s^2. But this doesnt work for Rectangles.","title":"Liskov Substitution Principle"},{"location":"COMP3161/wk9/SubTyping/#product-types","text":"Assuming Int \\(\\leq\\) Float Suppose I have a coercion function c: Int \\(\\mapsto\\) Float Can I use that to write coercion functions for handling 2 different product types. We draw the following coercion diagram: graph BT; IntXInt --> IntXFloat; IntXInt --> FloatXInt; FloatXInt --> FloatXFloat; IntXFloat --> FloatXFloat; And yes. We can create the coercion functions: c:: Int -> Float c n = Float n c1 :: (Int -> Int) -> (Int -> Float) (IntXFloat) c1 (n, m) = (n, c m) c2 :: (Int -> Int) -> (Float -> Int) (IntXFloat) c2 (n, m) = (c n, m) NOTE how we have 2 functions for 1 output c3 :: (Float -> Int) -> (Float -> Float) (FloatXFloat) c3 (n, m) = (n, c m) c4 :: (Int -> Float) -> (Float -> Float) (FloatXFloat) c4 (n, m) = (c n, m) So we can conclude for product types In order for a product type to be a subtype of another subtype, the rows before must be a subtype of the rows after. \\[ \\dfrac{\\tau_1 \\leq p_1 \\quad \\tau_2 \\leq p_2}{(\\tau_1\\times\\tau_2)\\leq(p_1 \\times p_2)} \\]","title":"Product Types"},{"location":"COMP3161/wk9/SubTyping/#sum-types","text":"Same as product types.","title":"Sum Types"},{"location":"COMP3161/wk9/SubTyping/#function-types","text":"Suppose we wanted to change a function from Int -> Int to Int -> Float. We assume c is Int -> Float. Say the function is named itoi, (int to int), and we want a coercion function named c1. itoi = take in an int and returns an int. so we want the result of itoi. or in other words for an \"int x\", \\x -> itoi x c1 itoi = take in an int, and make it a float we have c. c1 itoi = \\x -> c (itoi x) We cannot use coercion here normally. After applying the following relationships. graph BT; IntToInt --> IntToFloat; FloatToInt --> IntToInt; FloatToInt --> FloatToFloat; IntToFloat --> FloatToFloat; If I want a function from Float to Int","title":"Function Types"},{"location":"COMP3161/wk9/SubTyping/#invariants-co-variants-and-contravariants","text":"","title":"Invariants, Co-variants and Contravariants"},{"location":"Features/LaTeX%20Math%20Support/","text":"LaTeX Math Support \u00b6 LaTeX math is supported using MathJax. Inline math looks like \\(f(x) = x^2\\) . The input for this is $f(x) = x^2$ . Use $...$ . For a block of math, use $$...$$ on separate lines $$ F(x) = \\int^a_b \\frac{1}{2}x^4 $$ gives \\[ F(x) = \\int^a_b \\frac{1}{2}x^4 \\]","title":"LaTeX Math Support"},{"location":"Features/LaTeX%20Math%20Support/#latex-math-support","text":"LaTeX math is supported using MathJax. Inline math looks like \\(f(x) = x^2\\) . The input for this is $f(x) = x^2$ . Use $...$ . For a block of math, use $$...$$ on separate lines $$ F(x) = \\int^a_b \\frac{1}{2}x^4 $$ gives \\[ F(x) = \\int^a_b \\frac{1}{2}x^4 \\]","title":"LaTeX Math Support"},{"location":"Features/Mermaid%20Diagrams/","text":"Mermaid diagrams \u00b6 Here's the example from MkDocs Material documentation : graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Mermaid diagrams"},{"location":"Features/Mermaid%20Diagrams/#mermaid-diagrams","text":"Here's the example from MkDocs Material documentation : graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Mermaid diagrams"},{"location":"Features/Text%20Formatting/","text":"Text Formatting \u00b6 You can have lists like this first second third Or checklist lists to Get things done Also, get highlights and strikethroughs as above (similar to Obsidian). More formatting options for your webpage here . (but not compatible with Obsidian)","title":"Text Formatting"},{"location":"Features/Text%20Formatting/#text-formatting","text":"You can have lists like this first second third Or checklist lists to Get things done Also, get highlights and strikethroughs as above (similar to Obsidian). More formatting options for your webpage here . (but not compatible with Obsidian)","title":"Text Formatting"},{"location":"Topic%201/Note%201/","text":"Note 1 \u00b6 Example: link to Mermaid Diagrams under Features","title":"Note 1"},{"location":"Topic%201/Note%201/#note-1","text":"Example: link to Mermaid Diagrams under Features","title":"Note 1"},{"location":"Topic%201/Note%202/","text":"Note 2 \u00b6","title":"Note 2"},{"location":"Topic%201/Note%202/#note-2","text":"","title":"Note 2"}]}